{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "713e39c3-8bff-4b71-8017-7c56ce29017d",
   "metadata": {},
   "source": [
    "# DEFAULT COLLATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439f1c54-9bbd-4a6f-bb5c-1bb9b83a301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration simecek--Human_DNA_v0_DNABert6tokenized_stride1-43a5a14a7a9b8d0a\n",
      "Reusing dataset parquet (/home/jovyan/.cache/huggingface/datasets/simecek___parquet/simecek--Human_DNA_v0_DNABert6tokenized_stride1-43a5a14a7a9b8d0a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n",
      "Using custom data configuration simecek--Human_DNA_v0_DNABert6tokenized_stride1-43a5a14a7a9b8d0a\n",
      "Reusing dataset parquet (/home/jovyan/.cache/huggingface/datasets/simecek___parquet/simecek--Human_DNA_v0_DNABert6tokenized_stride1-43a5a14a7a9b8d0a/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification, DataCollatorForLanguageModeling, TextDataset\n",
    "from transformers import DistilBertConfig, DistilBertForMaskedLM\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DebertaConfig, DebertaForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"armheb/DNA_bert_6\")\n",
    "train_dset = load_dataset(\"simecek/Human_DNA_v0_DNABert6tokenized_stride1\", split='train[:10%]')\n",
    "test_dset = load_dataset(\"simecek/Human_DNA_v0_DNABert6tokenized_stride1\", split='test[:10%]')\n",
    "model_config = DebertaConfig(vocab_size=len(tokenizer.vocab), max_position_embeddings=512, num_hidden_layers=1)\n",
    "model = DebertaForMaskedLM(config=model_config)\n",
    "model.init_weights()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model',\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0, \n",
    "    push_to_hub=False,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    num_train_epochs=1,\n",
    "    save_total_limit=1,\n",
    "    # load_best_model_at_end=True,\n",
    "    logging_steps=1000,       \n",
    "    # save_steps=5000,\n",
    "    fp16=True,\n",
    "    # warmup_steps=1000,\n",
    ")\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c97ec92-218a-4106-8a07-be83b10a010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b36b80-a9cd-4ee6-90c7-e8c76c8938a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "tensor([ 867, 3455, 1519, 1966, 3755,    4, 2662, 2444, 1571, 2174,  492, 1954,\n",
      "        3706, 2523, 1886, 3435, 1437, 1638, 2444, 1569,    4,  457, 1816, 3154,\n",
      "         316,    4,  885,    4, 1804, 3107,  125,  486, 1930, 3611, 2142,  363,\n",
      "        1437, 1639, 2448, 1585, 2232,  721, 2870, 3275,  798, 3180,    4, 1654,\n",
      "           4, 1828, 3202,  506, 2010, 3930, 3417,    4, 1359, 1325, 1192,  660,\n",
      "        2628, 2308, 1027, 4094, 4074, 3994, 3674, 2395, 1375,    4, 1455, 1711,\n",
      "        2734, 2730, 2714, 2650, 2396, 1379, 1406, 1515, 1949, 3688, 2450,    4,\n",
      "        2261,  838, 3338, 1051,   94,  362,    4, 1635, 2430, 1516, 1955,    4,\n",
      "        2541, 1959, 3727,    4, 2214,  652,    4, 2172,    4, 1909, 3528, 1809,\n",
      "        3125,    4,  788, 3137,  246,    4, 3875, 3197,  486, 1930, 3610, 2140,\n",
      "         355, 1406, 1514, 2869, 3675, 2399, 1391, 1454,    4, 2711, 2639, 2349,\n",
      "           4,    4, 2605, 2214,  652, 2593, 2166,    4, 1820, 3170,  377, 1493,\n",
      "        1864,    4, 1082,  218,  859,    4, 1390,    4, 1697, 2680, 2516, 1859,\n",
      "        3327, 1006, 4011, 3742, 2667, 2462, 1641, 2456, 1619, 2367, 1261,  934,\n",
      "        3724, 2595, 2174,  492, 1953, 3701, 2503,    4, 3116,  161,  632, 2514,\n",
      "        1851, 3293,  869, 3461, 1543, 2063,   46,  170,  666, 2650, 2394, 1371,\n",
      "        1375, 1390, 1450, 1691, 3650, 2406, 1417, 1557, 2117,  262, 1034,    4,\n",
      "          87,  335, 1327, 1197,  680, 2706, 2619, 2270,  875, 3486, 1644, 2468,\n",
      "        1667, 2557, 2024, 3986,    4, 2267,  862, 3434, 1434,    4, 2390, 1353,\n",
      "        1304, 1107,  317, 1256,  915, 1583,    4,    4, 3809, 2936, 3537, 1845,\n",
      "        3270,    4, 3108,  129,  503, 1998, 3881,    4,  582, 2313, 1047, 1357,\n",
      "         295, 1167,  558, 2219,  669,    4, 2446, 1578, 2204,  612, 2436, 1538,\n",
      "        2044,    4, 3964,    4, 1918, 3562, 1947, 3678, 1423, 1429, 1607,    4,\n",
      "        1070,  170,  668, 2657, 2421, 1480,    4, 3126,  201,  789, 3144,  274,\n",
      "           4,    4,  856, 3410, 1337, 1237,  837, 3333, 1029,    7,   14,   44,\n",
      "           4,  631, 2509, 1831, 3213,  549, 2181,  518,    4,   24,   83,  317,\n",
      "        1254,  906, 3612, 2146,  377, 1493, 1863, 3341, 1064,    4,  565,    4,\n",
      "           4, 3105,  118,  459, 2787,    4,  427,    4, 2676, 2498, 1787, 3037,\n",
      "        3941, 3461, 1541,    4,    4,   36,  129,  503, 1998, 3883, 3230,  617,\n",
      "        2456, 1620,    4, 1271,  974, 3882, 3227,  606, 2410, 1436,    4, 2421,\n",
      "        1479, 1806, 3115,    4,    4, 2461, 1637, 2437, 1541, 2054,    4,   22,\n",
      "          74,  283, 1117,    4, 1425,    4, 2250,  794, 3164,  356,    4, 1538,\n",
      "        2042, 4059, 3934, 3436, 1441, 1656, 2513, 1846,    4,  794, 3164,  356,\n",
      "        1412, 1540, 2049, 4086, 4041,    4,    4,  290, 1147,  479, 1901, 3493,\n",
      "        1670, 2569, 2070,   75,  285, 1125,  389, 1542, 2058,   26,    4,  346,\n",
      "        1372, 1378, 1401,    4, 1864, 3345, 1078,  202,  795, 3167,  366, 1450,\n",
      "        1690, 2652, 2402, 1402, 1500, 1892, 3458, 1529, 2007, 3919,    4, 1190,\n",
      "         649,    4, 2120,    4,    4,  203,  799, 3181,  424, 1683, 2623, 2286,\n",
      "         938, 3740, 2659,    4, 1519, 1966, 3550, 2722, 2681, 2520, 1876, 3394,\n",
      "        1273,  981, 3912, 3345, 1080,  210,  828, 3300,  900, 3588, 2050, 4090,\n",
      "        4058, 3931, 3423, 1391, 1455, 1710, 2730, 2716, 2657, 2422, 1484, 1828,\n",
      "        3204,  513, 2038, 4042, 3868, 3172,  386, 1530, 2009, 3926,    4, 1306,\n",
      "        1113,  343, 1357,    4, 1162,    4, 2146, 2724])\n",
      "AGTTGC GTTGCC TTGCCC TGCCCT GCCCTC [MASK] CCTCAT CTCATG TCATGC CATGCT ATGCTG TGCTGT GCTGTT CTGTTC TGTTCT GTTCTC TTCTCA TCTCAT CTCATG TCATGA [MASK] ATGATA TGATAG GATAGT ATAGTG [MASK] AGTGAA [MASK] TGAATG GAATGC AATGCA ATGCAT TGCATT GCATTC CATTCT ATTCTC TTCTCA TCTCAC CTCACG TCACGA CACGAG ACGAGA CGAGAT GAGATC AGATCT GATCTG [MASK] TCTGAT [MASK] TGATGG GATGGT ATGGTT TGGTTT GGTTTT GTTTTA [MASK] TTTACC TTACCA TACCAG ACCAGG CCAGGG CAGGGG AGGGGC GGGGCT GGGCTT GGCTTT GCTTTT CTTTTC TTTTCC [MASK] TTCCCC TCCCCC CCCCCT CCCCTT CCCTTT CCTTTT CTTTTG TTTTGC TTTGCT TTGCTC TGCTCA GCTCAG CTCAGT [MASK] CAGTAA AGTAAT GTAATT TAATTC AATTCT ATTCTT [MASK] TCTTGC CTTGCT TTGCTG TGCTGC [MASK] CTGCCA TGCCAC GCCACC [MASK] CACCAT ACCATG [MASK] CATGTG [MASK] TGTGAA GTGAAG TGAAGA GAAGAA [MASK] AGAAGG GAAGGA AAGGAT [MASK] GGATGC GATGCA ATGCAT TGCATT GCATTT CATTTG ATTTGC TTTGCT TTGCTT CGAGAA GCTTTC CTTTCC TTTCCC TTCCCT [MASK] CCCTAC CCTACC CTACCA [MASK] [MASK] CCACCA CACCAT ACCATG CCATGA CATGAT [MASK] TGATTG GATTGT ATTGTA TTGTAA TGTAAG [MASK] TAAGTT AAGTTT AGTTTC [MASK] TTTCCT [MASK] TCCTGA CCTGAG CTGAGG TGAGGC GAGGCC AGGCCT GGCCTC GCCTCT CCTCTC CTCTCT TCTCTA CTCTAG TCTAGC CTAGCC TAGCCA AGCCAT GCCATG CCATGC CATGCT ATGCTG TGCTGA GCTGAA CTGAAC [MASK] GAACTG AACTGA ACTGAG CTGAGT TGAGTC GAGTCA AGTCAA GTCAAA TCAAAC CAAACC AAACCT AACCTT ACCTTT CCTTTT CTTTTT TTTTTC TTTTCC TTTCCT TTCCTT TCCTTC GCAGGT CTTCAT TTCATA TCATAA CATAAA ATAAAT TAAATT [MASK] AATTAC ATTACC TTACCC TACCCA ACCCAG CCCAGT CCAGTC CAGTCT AGTCTC GTCTCT TCTCTG CTCTGG TCTGGC CTGGCA TGGCAG GGCAGT [MASK] CAGTTC AGTTCT GTTCTT TTCTTT [MASK] CTTTAT TTTATA TTATAG TATAGC ATAGCA TAGCAG AGCAGC TCACCC [MASK] [MASK] GCGTGA CGTGAG GTGAGA TGAGAA GAGAAT [MASK] GAATGG AATGGA ATGGAC TGGACT GGACTA [MASK] ACTAAT CTAATA TAATAC TTTACA ATACAC TACACC ACACCT CACCTC ACCTCA [MASK] CTCACT TCACTT CACTTG ACTTGG CTTGGG TTGGGT TGGGTG [MASK] GGTGTG [MASK] TGTGCT GTGCTT TGCTTC GCTTCT TTCACC TTCTAA TCTAAC [MASK] TAACCT AACCTT ACCTTG CCTTGA CTTGAA TTGAAG [MASK] GAAGAT AAGATA AGATAA GATAAG ATAAGT [MASK] [MASK] AGTTAG GTTAGT TTAGTA TAGTAA AGTAAA GTAAAA TAAAAA AAAAAC AAAACT AAACTG [MASK] ACTGAC CTGACA TGACAC GACACA ACACAA CACAAA ACAAAT [MASK] AAATAG AATAGC ATAGCA TAGCAT AGCATT GCATTG CATTGT ATTGTA TTGTAA TGTAAC GTAACA TAACAG [MASK] ACAGAA [MASK] [MASK] GAATGA AATGAT ATGATC CCGTGC [MASK] ATCCTC [MASK] CCTCGG CTCGGT TCGGTC CGGTCA GGTCAA GTCAAA TCAAAA [MASK] [MASK] AAATGG AATGGA ATGGAC TGGACT GGACTC GACTCT ACTCTA CTCTAG TCTAGG [MASK] TAGGAC AGGACT GGACTT GACTTC ACTTCT CTTCTT TTCTTG [MASK] CTTGAA TTGAAC TGAACT GAACTC [MASK] [MASK] CTCTCA TCTCAA CTCAAA TCAAAA CAAAAT [MASK] AAATAT AATATT ATATTC TATTCA [MASK] TTCAGA [MASK] CAGATT AGATTT GATTTG ATTTGG [MASK] TTGGGT TGGGTT GGGTTC GGTTCT GTTCTG TTCTGA TCTGAG CTGAGA TGAGAT [MASK] AGATTT GATTTG ATTTGG TTTGGG TTGGGG TGGGGA GGGGAT GGGATA [MASK] [MASK] ATATGT TATGTC ATGTCC TGTCCA GTCCAA TCCAAT CCAATA CAATAT AATATC ATATCA TATCAA ATCAAA TCAAAT CAAATT AAATTT [MASK] ATTTTT TTTTTG TTTTGT TTTGTA [MASK] TGTAAG GTAAGA TAAGAT AAGATT AGATTC GATTCC ATTCCT TTCCTT TCCTTT CCTTTG CTTTGT TTTGTT TTGTTG TGTTGG GTTGGT TTGGTA TGGTAC GGTACC [MASK] TACCAT ACCATA [MASK] CATAAG [MASK] [MASK] AAGATC AGATCC GATCCA ATCCAG TCCAGC CCAGCC CAGCCT AGCCTT GCCTTG CCTTGC [MASK] TTGCCC TGCCCT GTGTCT CCCTGT CCTGTA CTGTAG TGTAGG GTAGGT TAGGTA AGGTAA GGTAAG GTAAGA TAAGAG AAGAGT AGAGTG GAGTGG AGTGGG GTGGGG TGGGGT GGGGTT GGGTTT GGTTTC GTTTCC TTTCCC TTCCCC TCCCCT CCCCTT CCCTTG CCTTGA CTTGAT TTGATG TGATGG GATGGG ATGGGA TGGGAT GGGATT GGATTG GATTGG ATTGGT TTGGTT TGGTTA GGTTAT [MASK] TTATTT TATTTA ATTTAC TTTACA [MASK] TACATT [MASK] CATTGT CCCTGG\n",
      "tensor([-100, -100, -100, -100, -100, 2717, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, 2166, -100, -100, -100,\n",
      "        -100, 1249, -100, 3526, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,  417, -100,\n",
      "        2508, -100, -100, -100, -100, -100, -100, 1367, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, 1391, 1455, 1711,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1593,\n",
      "        -100, -100, -100, -100, -100, -100, 1436, -100, -100, -100, -100, 3711,\n",
      "        -100, -100, -100, 2605, -100, -100, 2594, -100,  481, -100, -100, -100,\n",
      "        -100,  200, -100, -100, -100,  972, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, 1946, -100, -100, -100, -100, 1705, -100, -100, -100,\n",
      "        1191,  655, -100, -100, -100, 2593, -100,  458, -100, -100, -100, -100,\n",
      "        -100, 3346, -100, -100, -100, 3423, -100, 1452, -100, -100, -100, -100,\n",
      "        -100, -100, -100, 3742, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, 1953, -100, -100, 1806, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, 2653, -100, -100, -100, -100, -100, -100,   25,\n",
      "        -100, -100, -100, -100,  680, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, 3642, -100, -100, -100, -100, 1625, 2390, -100,\n",
      "        -100, -100, -100, -100, -100, 3648, 2290,  956, -100, -100, -100, -100,\n",
      "        -100,  780, -100, -100, -100, -100, -100, 3221, -100, -100, -100,   77,\n",
      "        -100, -100, -100, -100, -100, 2663, -100, -100, -100, -100, -100, -100,\n",
      "        -100, 4066, -100, 3555, -100, -100, -100, -100, 2409, -100, -100, 2319,\n",
      "        -100, -100, -100, -100, -100, -100, 1809, -100, -100, -100, -100, -100,\n",
      "        1082,  217, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "         161, -100, -100, -100, -100, -100, -100, -100, 2057, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100,  145, -100, 2246,\n",
      "         780, -100, -100, -100, 1823, 3182, -100, 1696, -100, -100, -100, -100,\n",
      "        -100, -100, -100, 2054,   12, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, 2369, -100, -100, -100, -100, -100, -100, -100, 1633, -100,\n",
      "        -100, -100, -100,  158,  619, -100, -100, -100, -100, -100,    9, -100,\n",
      "        -100, -100, -100,  360, -100, 1590, -100, -100, -100, -100, 1412, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, 3274, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, 3862, 3148, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,   90, -100,\n",
      "        -100, -100, -100, 1493, -100, -100, -100, -100, -100, -100,  366, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3373, -100,\n",
      "        -100, 2581, -100,  273, 1078, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, 2431, -100, -100, 3756, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 3402, -100,\n",
      "        -100, -100, -100, 1318, -100,  540, -100,  378])\n"
     ]
    }
   ],
   "source": [
    "for sample in trainer.get_train_dataloader():\n",
    "    print(sample.keys())\n",
    "    print(sample['input_ids'][0])\n",
    "    print(tokenizer.decode(sample['input_ids'][0]))\n",
    "    print(sample['labels'][0])\n",
    "    # print(tokenizer.decode(sample['labels'][0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e5c82df-a451-4fc5-8f1e-57ae63603020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizerFast(name_or_path='armheb/DNA_bert_6', vocab_size=4101, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1246b042-2885-4406-9b9d-9fd7e7e4761c",
   "metadata": {},
   "source": [
    "# CUSTOM COLLATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b34557da-423f-49ac-ad7d-6ce351b8ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.custom_masking.custom_collator import SubsequentCollator\n",
    "    \n",
    "myCollator=SubsequentCollator(tokenizer=tokenizer, mlm=True, mlm_probability=0.15, mask_fully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "218273cd-dd3c-4973-b255-1c0229c04cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubsequentCollator(tokenizer=PreTrainedTokenizerFast(name_or_path='armheb/DNA_bert_6', vocab_size=4101, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}), mlm=True, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f2cb0c-7fdb-44a5-b4f8-757a3dc2520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=myCollator,\n",
    "        train_dataset=train_dset,\n",
    "        eval_dataset=test_dset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "557a9fe3-2291-4ae0-9fcb-c2ddedbd3c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
      "tensor([ 867, 3455, 1519, 1966, 3755, 2717, 2662, 2444, 1571, 2174,  492, 1954,\n",
      "        3706, 2523, 1886, 3435, 1437, 1638, 2444, 1569, 2166,  457, 1816, 3154,\n",
      "         316, 1249,  885, 3526, 1804, 3107,  125,  486, 1930, 3611, 2142,  363,\n",
      "        1437, 1639, 2448, 1585, 2232,  721, 2870, 3275,  798, 3180,  417, 1654,\n",
      "        2508, 1828, 3202,  506, 2010, 3930, 3417, 1367, 1359, 1325, 1192,  660,\n",
      "        2628, 2308, 1027, 4094, 4074, 3994, 3674, 2395, 1375, 1391, 1455, 1711,\n",
      "        2734, 2730, 2714, 2650, 2396, 1379, 1406, 1515, 1949, 3688, 2450, 1593,\n",
      "        2261,  838, 3338, 1051,   94,  362, 1436, 1635, 2430, 1516, 1955, 3711,\n",
      "        2541, 1959, 3727, 2605, 2214,  652,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,    4,\n",
      "           4,    4,    4,    4,    4,    4,    4,    4,    4,    4,  632, 2514,\n",
      "        1851, 3293,  869, 3461, 1543, 2063,   46,  170,  666, 2650, 2394, 1371,\n",
      "        1375, 1390, 1450, 1691, 2653, 2406, 1417, 1557, 2117,  262, 1034,   25,\n",
      "          87,  335, 1327, 1197,  680, 2706, 2619, 2270,  875, 3486, 1644, 2468,\n",
      "        1667, 2557, 2024, 3986, 3642, 2267,  862, 3434, 1434, 1625, 2390, 1353,\n",
      "        1304, 1107,  317, 1256,  915, 3648, 2290,  956, 3809, 2936, 3537, 1845,\n",
      "        3270,  780, 3108,  129,  503, 1998, 3881, 3221,  582, 2313, 1047,   77,\n",
      "         295, 1167,  558, 2219,  669, 2663, 2446, 1578, 2204,  612, 2436, 1538,\n",
      "        2044, 4066, 3964, 3555, 1918, 3562, 1947, 3678, 2409, 1429, 1607, 2319,\n",
      "        1070,  170,  668, 2657, 2421, 1480, 1809, 3126,  201,  789, 3144,  274,\n",
      "        1082,  217,  856, 3410, 1337, 1237,  837, 3333, 1029,    7,   14,   44,\n",
      "         161,  631, 2509, 1831, 3213,  549, 2181,  518, 2057,   24,   83,  317,\n",
      "        1254,  906, 3612, 2146,  377, 1493, 1863, 3341, 1064,  145,  565, 2246,\n",
      "         780, 3105,  118,  459, 1823, 3182,  427, 1696, 2676, 2498, 1787, 3037,\n",
      "        3941, 3461, 1541, 2054,   12,   36,  129,  503, 1998, 3883, 3230,  617,\n",
      "        2456, 1620, 2369, 1271,  974, 3882, 3227,  606, 2410, 1436, 1633, 2421,\n",
      "        1479, 1806, 3115,  158,  619, 2461, 1637, 2437, 1541, 2054,    9,   22,\n",
      "          74,  283, 1117,  360, 1425, 1590, 2250,  794, 3164,  356, 1412, 1538,\n",
      "        2042, 4059, 3934, 3436, 1441, 1656, 2513, 1846, 3274,  794, 3164,  356,\n",
      "        1412, 1540, 2049, 4086, 4041, 3862, 3148,  290, 1147,  479, 1901, 3493,\n",
      "        1670, 2569, 2070,   75,  285, 1125,  389, 1542, 2058,   26,   90,  346,\n",
      "        1372, 1378, 1401, 1493, 1864, 3345, 1078,  202,  795, 3167,  366, 1450,\n",
      "        1690, 2652, 2402, 1402, 1500, 1892, 3458, 1529, 2007, 3919, 3373, 1190,\n",
      "         649, 2581, 2120,  273, 1078,  203,  799, 3181,  424, 1683, 2623, 2286,\n",
      "         938, 3740, 2659, 2431, 1519, 1966, 3756, 2722, 2681, 2520, 1876, 3394,\n",
      "        1273,  981, 3912, 3345, 1080,  210,  828, 3300,  900, 3588, 2050, 4090,\n",
      "        4058, 3931, 3423, 1391, 1455, 1710, 2730, 2716, 2657, 2422, 1484, 1828,\n",
      "        3204,  513, 2038, 4042, 3868, 3172,  386, 1530, 2009, 3926, 3402, 1306,\n",
      "        1113,  343, 1357, 1318, 1162,  540, 2146,  378])\n",
      "AGTTGC GTTGCC TTGCCC TGCCCT GCCCTC CCCTCA CCTCAT CTCATG TCATGC CATGCT ATGCTG TGCTGT GCTGTT CTGTTC TGTTCT GTTCTC TTCTCA TCTCAT CTCATG TCATGA CATGAT ATGATA TGATAG GATAGT ATAGTG TAGTGA AGTGAA GTGAAT TGAATG GAATGC AATGCA ATGCAT TGCATT GCATTC CATTCT ATTCTC TTCTCA TCTCAC CTCACG TCACGA CACGAG ACGAGA CGAGAT GAGATC AGATCT GATCTG ATCTGA TCTGAT CTGATG TGATGG GATGGT ATGGTT TGGTTT GGTTTT GTTTTA TTTTAC TTTACC TTACCA TACCAG ACCAGG CCAGGG CAGGGG AGGGGC GGGGCT GGGCTT GGCTTT GCTTTT CTTTTC TTTTCC TTTCCC TTCCCC TCCCCC CCCCCT CCCCTT CCCTTT CCTTTT CTTTTG TTTTGC TTTGCT TTGCTC TGCTCA GCTCAG CTCAGT TCAGTA CAGTAA AGTAAT GTAATT TAATTC AATTCT ATTCTT TTCTTG TCTTGC CTTGCT TTGCTG TGCTGC GCTGCC CTGCCA TGCCAC GCCACC CCACCA CACCAT ACCATG [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ACTGAG CTGAGT TGAGTC GAGTCA AGTCAA GTCAAA TCAAAC CAAACC AAACCT AACCTT ACCTTT CCTTTT CTTTTT TTTTTC TTTTCC TTTCCT TTCCTT TCCTTC CCTTCA CTTCAT TTCATA TCATAA CATAAA ATAAAT TAAATT AAATTA AATTAC ATTACC TTACCC TACCCA ACCCAG CCCAGT CCAGTC CAGTCT AGTCTC GTCTCT TCTCTG CTCTGG TCTGGC CTGGCA TGGCAG GGCAGT GCAGTT CAGTTC AGTTCT GTTCTT TTCTTT TCTTTA CTTTAT TTTATA TTATAG TATAGC ATAGCA TAGCAG AGCAGC GCAGCG CAGCGT AGCGTG GCGTGA CGTGAG GTGAGA TGAGAA GAGAAT AGAATG GAATGG AATGGA ATGGAC TGGACT GGACTA GACTAA ACTAAT CTAATA TAATAC AATACA ATACAC TACACC ACACCT CACCTC ACCTCA CCTCAC CTCACT TCACTT CACTTG ACTTGG CTTGGG TTGGGT TGGGTG GGGTGT GGTGTG GTGTGC TGTGCT GTGCTT TGCTTC GCTTCT CTTCTA TTCTAA TCTAAC CTAACC TAACCT AACCTT ACCTTG CCTTGA CTTGAA TTGAAG TGAAGA GAAGAT AAGATA AGATAA GATAAG ATAAGT TAAGTT AAGTTA AGTTAG GTTAGT TTAGTA TAGTAA AGTAAA GTAAAA TAAAAA AAAAAC AAAACT AAACTG AACTGA ACTGAC CTGACA TGACAC GACACA ACACAA CACAAA ACAAAT CAAATA AAATAG AATAGC ATAGCA TAGCAT AGCATT GCATTG CATTGT ATTGTA TTGTAA TGTAAC GTAACA TAACAG AACAGA ACAGAA CAGAAT AGAATG GAATGA AATGAT ATGATC TGATCC GATCCT ATCCTC TCCTCG CCTCGG CTCGGT TCGGTC CGGTCA GGTCAA GTCAAA TCAAAA CAAAAT AAAATG AAATGG AATGGA ATGGAC TGGACT GGACTC GACTCT ACTCTA CTCTAG TCTAGG CTAGGA TAGGAC AGGACT GGACTT GACTTC ACTTCT CTTCTT TTCTTG TCTTGA CTTGAA TTGAAC TGAACT GAACTC AACTCT ACTCTC CTCTCA TCTCAA CTCAAA TCAAAA CAAAAT AAAATA AAATAT AATATT ATATTC TATTCA ATTCAG TTCAGA TCAGAT CAGATT AGATTT GATTTG ATTTGG TTTGGG TTGGGT TGGGTT GGGTTC GGTTCT GTTCTG TTCTGA TCTGAG CTGAGA TGAGAT GAGATT AGATTT GATTTG ATTTGG TTTGGG TTGGGG TGGGGA GGGGAT GGGATA GGATAT GATATG ATATGT TATGTC ATGTCC TGTCCA GTCCAA TCCAAT CCAATA CAATAT AATATC ATATCA TATCAA ATCAAA TCAAAT CAAATT AAATTT AATTTT ATTTTT TTTTTG TTTTGT TTTGTA TTGTAA TGTAAG GTAAGA TAAGAT AAGATT AGATTC GATTCC ATTCCT TTCCTT TCCTTT CCTTTG CTTTGT TTTGTT TTGTTG TGTTGG GTTGGT TTGGTA TGGTAC GGTACC GTACCA TACCAT ACCATA CCATAA CATAAG ATAAGA TAAGAT AAGATC AGATCC GATCCA ATCCAG TCCAGC CCAGCC CAGCCT AGCCTT GCCTTG CCTTGC CTTGCC TTGCCC TGCCCT GCCCTG CCCTGT CCTGTA CTGTAG TGTAGG GTAGGT TAGGTA AGGTAA GGTAAG GTAAGA TAAGAG AAGAGT AGAGTG GAGTGG AGTGGG GTGGGG TGGGGT GGGGTT GGGTTT GGTTTC GTTTCC TTTCCC TTCCCC TCCCCT CCCCTT CCCTTG CCTTGA CTTGAT TTGATG TGATGG GATGGG ATGGGA TGGGAT GGGATT GGATTG GATTGG ATTGGT TTGGTT TGGTTA GGTTAT GTTATT TTATTT TATTTA ATTTAC TTTACA TTACAT TACATT ACATTG CATTGT ATTGTT\n",
      "tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, 2594, 2172,  481, 1909, 3528, 1809,\n",
      "        3125,  200,  788, 3137,  246,  972, 3875, 3197,  486, 1930, 3610, 2140,\n",
      "         355, 1406, 1514, 1946, 3675, 2399, 1391, 1454, 1705, 2711, 2639, 2349,\n",
      "        1191,  655, 2605, 2214,  652, 2593, 2166,  458, 1820, 3170,  377, 1493,\n",
      "        1864, 3346, 1082,  218,  859, 3423, 1390, 1452, 1697, 2680, 2516, 1859,\n",
      "        3327, 1006, 4011, 3742, 2667, 2462, 1641, 2456, 1619, 2367, 1261,  934,\n",
      "        3724, 2595, 2174,  492, 1953, 3701, 2503, 1806, 3116,  161, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100])\n"
     ]
    }
   ],
   "source": [
    "for sample in trainer.get_train_dataloader():\n",
    "    print(sample.keys())\n",
    "    print(sample['input_ids'][0])\n",
    "    print(tokenizer.decode(sample['input_ids'][0]))\n",
    "    print(sample['labels'][0])\n",
    "    # print(tokenizer.decode(sample['labels'][0]))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-env-myCudaCondaEnv-py",
   "language": "python",
   "name": "conda-env-mycudacondaenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
