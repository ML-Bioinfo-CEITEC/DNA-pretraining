{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gyck9b-I6tpY",
    "outputId": "eee2e692-7936-4250-9b27-789db827718d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('demo_coding_vs_intergenomic_seqs', 0)]\n"
     ]
    }
   ],
   "source": [
    "### Parameters\n",
    "RANDOMIZE_WEIGHTS = True \n",
    "RESIZE_EMBEDDINGS = True #only used for using tokenizers with different vocab_size than orig. model\n",
    "\n",
    "OUTPUT_PATH = './NAME_metrics.csv'\n",
    "\n",
    "MODEL_NAME = \"armheb/DNA_bert_6\"\n",
    "TOKENIZER_NAME = \"armheb/DNA_bert_6\"\n",
    "K = 7\n",
    "STRIDE = 1\n",
    "\n",
    "\n",
    "# MODEL_NAME = \"Vlasta/DNADebertaSentencepiece30k\"\n",
    "# TOKENIZER_NAME = \"Vlasta/DNADebertaSentencepiece30k\"\n",
    "# K = None\n",
    "# STRIDE = None\n",
    "\n",
    "\n",
    "\n",
    "# All datasets\n",
    "# DATASETS = [('demo_coding_vs_intergenomic_seqs', 0),\n",
    "#  ('demo_human_or_worm', 0), ('human_enhancers_cohn', 0), ('human_enhancers_ensembl', 0),\n",
    "#  ('human_ensembl_regulatory', 0), ('human_nontata_promoters', 0), ('human_ocr_ensembl', 0)]\n",
    "\n",
    "# Quick check dataset\n",
    "# DATASETS = [('demo_human_or_worm', 0)]\n",
    "\n",
    "\n",
    "# Binary classification datasets (without human_ensembl_regulatory)\n",
    "# DATASETS = [('demo_coding_vs_intergenomic_seqs', 0),\n",
    "#  ('demo_human_or_worm', 0), ('human_enhancers_cohn', 0), ('human_enhancers_ensembl', 0),\n",
    "#   ('human_nontata_promoters', 0), ('human_ocr_ensembl', 0)]\n",
    "DATASETS = [('demo_coding_vs_intergenomic_seqs', 0)]\n",
    "\n",
    "# if ensemble refuses connection - \"[Errno 104] Connection reset by peer\", use attribute use_cloud_cache=True\n",
    "BENCHMARKS_FOLDER = '/home/jovyan/.genomic_benchmarks'\n",
    "USE_CLOUD_CACHE = True\n",
    "# if less than 1, only this fraction of each dataset is used\n",
    "DATASET_THINING = 1 \n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ACCUMULATION = 2\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 100 \n",
    "RUNS = 1\n",
    "\n",
    "print(DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cdna_one/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "warmup_ratio = 0.05 #5 epochs (for 100 epochs total train)\n",
    "if(RANDOMIZE_WEIGHTS):\n",
    "    warmup_ratio = 0\n",
    "def get_trainargs():\n",
    "    return TrainingArguments(\n",
    "        'outputs', \n",
    "        learning_rate=LEARNING_RATE, \n",
    "        warmup_ratio=warmup_ratio, \n",
    "        lr_scheduler_type='linear',\n",
    "        fp16=True,\n",
    "        evaluation_strategy=\"epoch\", \n",
    "        per_device_train_batch_size=BATCH_SIZE, \n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=ACCUMULATION,\n",
    "        num_train_epochs=EPOCHS, \n",
    "        weight_decay=0.01,\n",
    "        save_strategy='epoch',\n",
    "        seed=randrange(1,10001), \n",
    "        report_to='none',\n",
    "        load_best_model_at_end=True,\n",
    "    )\n",
    "#early stopping 5 epochs\n",
    "callbacks= [\n",
    "    EarlyStoppingCallback(early_stopping_patience=5, early_stopping_threshold=0.0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lq7oMV6baan7",
    "outputId": "6aa53001-2ddb-4cbf-ec5d-d296b168bf2c"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "if(K is not None and K>6):\n",
    "    alphabet = ('A', 'C', 'T', 'G')\n",
    "    vocab = list(map(''.join, product(alphabet, repeat=K)))\n",
    "    tokenizer.add_tokens(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "aolqScmmYaIs",
    "outputId": "5a706116-b020-47ba-a298-57e5d75080dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 7109, 16136, 19473, 16440, 4308, 4930, 7417, 17366, 8010, 19737, 17495, 8527, 5422, 9387, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] ATGGAAA TGGAAAG GGAAAGA GAAAGAG AAAGAGG AAGAGGC AGAGGCA GAGGCAC AGGCACC GGCACCA GCACCAT CACCATT ACCATTC CCATTCT [SEP]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmers_strideK(s, k=K):\n",
    "    return [s[i:i + k] for i in range(0, len(s), k) if i + k <= len(s)]\n",
    "\n",
    "def kmers_stride1(s, k=K):\n",
    "    return [s[i:i + k] for i in range(0, len(s)-k+1)]\n",
    "\n",
    "if (STRIDE == 1):\n",
    "  kmers = kmers_stride1\n",
    "else:\n",
    "  kmers = kmers_strideK\n",
    "\n",
    "# function used for the actual tokenization\n",
    "if(K is not None):\n",
    "    def tok_func(x): return tokenizer(\" \".join(kmers(x[\"seq\"])), truncation=True)\n",
    "else:\n",
    "    def tok_func(x): return tokenizer(x[\"seq\"], truncation=True)\n",
    "\n",
    "# example\n",
    "example = tok_func({'seq': 'ATGGAAAGAGGCACCATTCT'})    \n",
    "print(example)\n",
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfoAktdfUsl1"
   },
   "source": [
    "## Download benchmark datasets and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b1389c9d504e41b3bdc51a8805cfee5e",
      "cb813c47be474313bb9bdbec8327ddaf",
      "d33afcc4a33442d090d29ff1284e49ec",
      "dd67380f41b548cc8882b31219ab36de",
      "628aa13a3c8140be876e937c87d111be",
      "b59de534cb5b4d4486c6033c8f7bb4c2",
      "e3f54f15415a4a27bb77a7c06410db57",
      "01d30f8e4fde43fc8a3e4593d3932d47",
      "240183ed0048432e8f953293ea24bdce",
      "e9ca594da9214565bf101c528d74fc3d",
      "c04acfbcab1549e891f2320534af0400"
     ]
    },
    "id": "I3ZRsNqx7LNa",
    "outputId": "3562075e-a73f-4bc5-c977-f5d761762144"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1216.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from genomic_benchmarks.loc2seq import download_dataset\n",
    "from genomic_benchmarks.data_check.info import is_downloaded\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "for dataset_name, dataset_version in tqdm(DATASETS):\n",
    "    if not is_downloaded(dataset_name):\n",
    "        download_dataset(dataset_name, version=dataset_version, use_cloud_cache=USE_CLOUD_CACHE)\n",
    "\n",
    "benchmark_root = Path(BENCHMARKS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to extract dataframe metrics row from training logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_from_history(history, dataset_name):\n",
    "    eval_dicts = [x for x in history if 'eval_loss' in x]\n",
    "    test_dicts = [x for x in history if 'test_loss' in x]\n",
    "    test_log = test_dicts[0]\n",
    "    test_acc = test_log['test_accuracy']\n",
    "    test_f1 = test_log['test_f1']\n",
    "    test_loss = test_log['test_loss']\n",
    "    test_precision = test_log['test_precision']\n",
    "    test_recall = test_log['test_recall']\n",
    "    test_auroc_macro = test_log['test_rocauc_0_roc_auc']\n",
    "    test_auroc_weighted = test_log['test_rocauc_1_roc_auc']\n",
    "    test_pr_auc = test_log['test_pr_auc']\n",
    "    \n",
    "    \n",
    "    min_loss_dict = min(eval_dicts, key=lambda x: x['eval_loss'])\n",
    "    min_loss_epoch = min_loss_dict['epoch']\n",
    "    # max_f1_dict = max(eval_dicts, key=lambda x: x['eval_f1'])\n",
    "    # max_acc_dict = max(eval_dicts, key=lambda x: x['eval_accuracy'])\n",
    "    row = {\n",
    "        'dataset':dataset_name,\n",
    "        'test_acc':test_acc,\n",
    "        'test_f1':test_f1,\n",
    "        'test_loss':test_loss,\n",
    "        'test_precision':test_precision,\n",
    "        'test_recall':test_recall,\n",
    "        'test_auroc_macro':test_auroc_macro,\n",
    "        'test_auroc_weighted':test_auroc_weighted,\n",
    "        'test_pr_auc':test_pr_auc,\n",
    "        \n",
    "        'min_valid_loss_epoch':min_loss_epoch,\n",
    "        'min_valid_loss_log':min_loss_dict,\n",
    "        # 'max_valid_f1_log':max_f1_dict,\n",
    "        # 'max_valid_acc_log':max_acc_dict,\n",
    "    }\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cYuLrCnUz-K"
   },
   "source": [
    "## Looping through datasets, fine-tuning the model for each of them, logging metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "binary_metrics = evaluate.combine([\n",
    "    'accuracy',\n",
    "    'f1',\n",
    "    'recall',\n",
    "    'precision',\n",
    "    #Order of roc_auc matters for logging -> macro first, then weighted\n",
    "    evaluate.load('roc_auc', average='macro'),\n",
    "    evaluate.load('roc_auc', average='weighted'),\n",
    "    evaluate.load(\"Vlasta/pr_auc\"),\n",
    "])\n",
    "# binary_metrics.compute(references=[0,1,1,1], predictions=[0,0,1,1], prediction_scores=[0.4,0.3,0.6,0.9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_C7mdPSn-0Pl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100000 [00:00<?, ?ex/s]\u001b[A\n",
      "  0%|          | 213/100000 [00:00<00:46, 2129.36ex/s]\u001b[A\n",
      "  0%|          | 433/100000 [00:00<00:45, 2167.70ex/s]\u001b[A\n",
      "  1%|          | 651/100000 [00:00<00:45, 2170.58ex/s]\u001b[A\n",
      "  1%|          | 869/100000 [00:00<00:46, 2141.48ex/s]\u001b[A\n",
      "  1%|          | 1084/100000 [00:00<00:52, 1892.69ex/s]\u001b[A\n",
      "  1%|▏         | 1304/100000 [00:00<00:49, 1985.95ex/s]\u001b[A\n",
      "  2%|▏         | 1526/100000 [00:00<00:47, 2056.96ex/s]\u001b[A\n",
      "  2%|▏         | 1744/100000 [00:00<00:46, 2092.20ex/s]\u001b[A\n",
      "  2%|▏         | 1963/100000 [00:00<00:46, 2118.01ex/s]\u001b[A\n",
      "  2%|▏         | 2177/100000 [00:01<00:51, 1916.86ex/s]\u001b[A\n",
      "  2%|▏         | 2400/100000 [00:01<00:48, 2002.27ex/s]\u001b[A\n",
      "  3%|▎         | 2611/100000 [00:01<00:47, 2032.18ex/s]\u001b[A\n",
      "  3%|▎         | 2821/100000 [00:01<00:47, 2050.67ex/s]\u001b[A\n",
      "  3%|▎         | 3029/100000 [00:01<00:50, 1907.34ex/s]\u001b[A\n",
      "  3%|▎         | 3257/100000 [00:01<00:48, 2011.16ex/s]\u001b[A\n",
      "  3%|▎         | 3487/100000 [00:01<00:46, 2091.32ex/s]\u001b[A\n",
      "  4%|▎         | 3717/100000 [00:01<00:44, 2149.59ex/s]\u001b[A\n",
      "  4%|▍         | 3947/100000 [00:01<00:43, 2193.24ex/s]\u001b[A\n",
      "  4%|▍         | 4168/100000 [00:02<00:47, 2022.10ex/s]\u001b[A\n",
      "  4%|▍         | 4398/100000 [00:02<00:45, 2098.19ex/s]\u001b[A\n",
      "  5%|▍         | 4627/100000 [00:02<00:44, 2151.45ex/s]\u001b[A\n",
      "  5%|▍         | 4855/100000 [00:02<00:43, 2188.13ex/s]\u001b[A\n",
      "  5%|▌         | 5076/100000 [00:02<00:47, 1992.30ex/s]\u001b[A\n",
      "  5%|▌         | 5300/100000 [00:02<00:45, 2059.63ex/s]\u001b[A\n",
      "  6%|▌         | 5526/100000 [00:02<00:44, 2114.03ex/s]\u001b[A\n",
      "  6%|▌         | 5752/100000 [00:02<00:43, 2155.10ex/s]\u001b[A\n",
      "  6%|▌         | 5979/100000 [00:02<00:42, 2188.40ex/s]\u001b[A\n",
      "  6%|▌         | 6200/100000 [00:03<00:46, 2009.68ex/s]\u001b[A\n",
      "  6%|▋         | 6428/100000 [00:03<00:44, 2082.98ex/s]\u001b[A\n",
      "  7%|▋         | 6655/100000 [00:03<00:43, 2133.98ex/s]\u001b[A\n",
      "  7%|▋         | 6883/100000 [00:03<00:42, 2175.06ex/s]\u001b[A\n",
      "  7%|▋         | 7103/100000 [00:03<00:46, 1992.57ex/s]\u001b[A\n",
      "  7%|▋         | 7331/100000 [00:03<00:44, 2069.94ex/s]\u001b[A\n",
      "  8%|▊         | 7559/100000 [00:03<00:43, 2128.10ex/s]\u001b[A\n",
      "  8%|▊         | 7789/100000 [00:03<00:42, 2176.41ex/s]\u001b[A\n",
      "  8%|▊         | 8009/100000 [00:03<00:45, 2011.96ex/s]\u001b[A\n",
      "  8%|▊         | 8235/100000 [00:03<00:44, 2079.32ex/s]\u001b[A\n",
      "  8%|▊         | 8464/100000 [00:04<00:42, 2137.13ex/s]\u001b[A\n",
      "  9%|▊         | 8692/100000 [00:04<00:41, 2177.10ex/s]\u001b[A\n",
      "  9%|▉         | 8918/100000 [00:04<00:41, 2200.39ex/s]\u001b[A\n",
      "  9%|▉         | 9140/100000 [00:04<00:44, 2020.97ex/s]\u001b[A\n",
      "  9%|▉         | 9359/100000 [00:04<00:43, 2066.85ex/s]\u001b[A\n",
      " 10%|▉         | 9587/100000 [00:04<00:42, 2126.51ex/s]\u001b[A\n",
      " 10%|▉         | 9819/100000 [00:04<00:41, 2181.30ex/s]\u001b[A\n",
      " 10%|█         | 10040/100000 [00:04<00:44, 2016.99ex/s]\u001b[A\n",
      " 10%|█         | 10263/100000 [00:04<00:43, 2075.16ex/s]\u001b[A\n",
      " 10%|█         | 10492/100000 [00:05<00:41, 2134.98ex/s]\u001b[A\n",
      " 11%|█         | 10721/100000 [00:05<00:40, 2177.80ex/s]\u001b[A\n",
      " 11%|█         | 10941/100000 [00:05<00:41, 2168.75ex/s]\u001b[A\n",
      " 11%|█         | 11160/100000 [00:05<00:44, 1993.84ex/s]\u001b[A\n",
      " 11%|█▏        | 11387/100000 [00:05<00:42, 2069.35ex/s]\u001b[A\n",
      " 12%|█▏        | 11614/100000 [00:05<00:41, 2124.80ex/s]\u001b[A\n",
      " 12%|█▏        | 11836/100000 [00:05<00:40, 2151.23ex/s]\u001b[A\n",
      " 12%|█▏        | 12053/100000 [00:05<00:44, 1986.85ex/s]\u001b[A\n",
      " 12%|█▏        | 12282/100000 [00:05<00:42, 2068.63ex/s]\u001b[A\n",
      " 13%|█▎        | 12512/100000 [00:05<00:41, 2133.29ex/s]\u001b[A\n",
      " 13%|█▎        | 12743/100000 [00:06<00:39, 2181.81ex/s]\u001b[A\n",
      " 13%|█▎        | 12974/100000 [00:06<00:39, 2217.02ex/s]\u001b[A\n",
      " 13%|█▎        | 13198/100000 [00:06<00:42, 2028.25ex/s]\u001b[A\n",
      " 13%|█▎        | 13428/100000 [00:06<00:41, 2103.30ex/s]\u001b[A\n",
      " 14%|█▎        | 13660/100000 [00:06<00:39, 2163.03ex/s]\u001b[A\n",
      " 14%|█▍        | 13890/100000 [00:06<00:39, 2201.72ex/s]\u001b[A\n",
      " 14%|█▍        | 14113/100000 [00:06<00:43, 1975.75ex/s]\u001b[A\n",
      " 14%|█▍        | 14343/100000 [00:06<00:41, 2061.86ex/s]\u001b[A\n",
      " 15%|█▍        | 14570/100000 [00:06<00:40, 2119.16ex/s]\u001b[A\n",
      " 15%|█▍        | 14796/100000 [00:07<00:39, 2157.72ex/s]\u001b[A\n",
      " 15%|█▌        | 15015/100000 [00:07<00:43, 1973.03ex/s]\u001b[A\n",
      " 15%|█▌        | 15239/100000 [00:07<00:41, 2045.50ex/s]\u001b[A\n",
      " 15%|█▌        | 15469/100000 [00:07<00:39, 2114.91ex/s]\u001b[A\n",
      " 16%|█▌        | 15696/100000 [00:07<00:39, 2158.17ex/s]\u001b[A\n",
      " 16%|█▌        | 15924/100000 [00:07<00:38, 2193.20ex/s]\u001b[A\n",
      " 16%|█▌        | 16146/100000 [00:07<00:41, 2012.31ex/s]\u001b[A\n",
      " 16%|█▋        | 16370/100000 [00:07<00:40, 2075.26ex/s]\u001b[A\n",
      " 17%|█▋        | 16596/100000 [00:07<00:39, 2127.01ex/s]\u001b[A\n",
      " 17%|█▋        | 16818/100000 [00:08<00:38, 2153.32ex/s]\u001b[A\n",
      " 17%|█▋        | 17036/100000 [00:08<00:42, 1947.39ex/s]\u001b[A\n",
      " 17%|█▋        | 17253/100000 [00:08<00:41, 2007.41ex/s]\u001b[A\n",
      " 17%|█▋        | 17475/100000 [00:08<00:39, 2065.10ex/s]\u001b[A\n",
      " 18%|█▊        | 17696/100000 [00:08<00:39, 2105.81ex/s]\u001b[A\n",
      " 18%|█▊        | 17921/100000 [00:08<00:38, 2146.89ex/s]\u001b[A\n",
      " 18%|█▊        | 18138/100000 [00:08<00:41, 1966.27ex/s]\u001b[A\n",
      " 18%|█▊        | 18364/100000 [00:08<00:39, 2045.64ex/s]\u001b[A\n",
      " 19%|█▊        | 18591/100000 [00:08<00:38, 2107.41ex/s]\u001b[A\n",
      " 19%|█▉        | 18815/100000 [00:09<00:37, 2145.36ex/s]\u001b[A\n",
      " 19%|█▉        | 19032/100000 [00:09<00:41, 1947.64ex/s]\u001b[A\n",
      " 19%|█▉        | 19251/100000 [00:09<00:40, 2012.54ex/s]\u001b[A\n",
      " 19%|█▉        | 19478/100000 [00:09<00:38, 2084.81ex/s]\u001b[A\n",
      " 20%|█▉        | 19697/100000 [00:09<00:38, 2113.03ex/s]\u001b[A\n",
      " 20%|█▉        | 19919/100000 [00:09<00:37, 2141.99ex/s]\u001b[A\n",
      " 20%|██        | 20135/100000 [00:09<00:40, 1963.75ex/s]\u001b[A\n",
      " 20%|██        | 20354/100000 [00:09<00:39, 2025.26ex/s]\u001b[A\n",
      " 21%|██        | 20572/100000 [00:09<00:38, 2068.74ex/s]\u001b[A\n",
      " 21%|██        | 20791/100000 [00:09<00:37, 2101.72ex/s]\u001b[A\n",
      " 21%|██        | 21004/100000 [00:10<00:41, 1922.60ex/s]\u001b[A\n",
      " 21%|██        | 21229/100000 [00:10<00:39, 2010.95ex/s]\u001b[A\n",
      " 21%|██▏       | 21452/100000 [00:10<00:37, 2070.14ex/s]\u001b[A\n",
      " 22%|██▏       | 21662/100000 [00:10<00:37, 2077.98ex/s]\u001b[A\n",
      " 22%|██▏       | 21881/100000 [00:10<00:37, 2109.35ex/s]\u001b[A\n",
      " 22%|██▏       | 22094/100000 [00:10<00:40, 1933.38ex/s]\u001b[A\n",
      " 22%|██▏       | 22300/100000 [00:10<00:39, 1968.02ex/s]\u001b[A\n",
      " 23%|██▎       | 22514/100000 [00:10<00:38, 2016.22ex/s]\u001b[A\n",
      " 23%|██▎       | 22729/100000 [00:10<00:37, 2053.68ex/s]\u001b[A\n",
      " 23%|██▎       | 22955/100000 [00:11<00:36, 2111.92ex/s]\u001b[A\n",
      " 23%|██▎       | 23168/100000 [00:11<00:39, 1927.20ex/s]\u001b[A\n",
      " 23%|██▎       | 23393/100000 [00:11<00:37, 2016.15ex/s]\u001b[A\n",
      " 24%|██▎       | 23609/100000 [00:11<00:37, 2054.92ex/s]\u001b[A\n",
      " 24%|██▍       | 23838/100000 [00:11<00:35, 2120.83ex/s]\u001b[A\n",
      " 24%|██▍       | 24053/100000 [00:11<00:38, 1952.59ex/s]\u001b[A\n",
      " 24%|██▍       | 24280/100000 [00:11<00:37, 2039.92ex/s]\u001b[A\n",
      " 25%|██▍       | 24510/100000 [00:11<00:35, 2113.31ex/s]\u001b[A\n",
      " 25%|██▍       | 24740/100000 [00:11<00:34, 2165.36ex/s]\u001b[A\n",
      " 25%|██▍       | 24971/100000 [00:12<00:33, 2207.45ex/s]\u001b[A\n",
      " 25%|██▌       | 25194/100000 [00:12<00:36, 2031.79ex/s]\u001b[A\n",
      " 25%|██▌       | 25424/100000 [00:12<00:35, 2105.33ex/s]\u001b[A\n",
      " 26%|██▌       | 25655/100000 [00:12<00:34, 2161.29ex/s]\u001b[A\n",
      " 26%|██▌       | 25886/100000 [00:12<00:33, 2202.30ex/s]\u001b[A\n",
      " 26%|██▌       | 26109/100000 [00:12<00:36, 2031.14ex/s]\u001b[A\n",
      " 26%|██▋       | 26338/100000 [00:12<00:35, 2102.03ex/s]\u001b[A\n",
      " 27%|██▋       | 26563/100000 [00:12<00:34, 2141.51ex/s]\u001b[A\n",
      " 27%|██▋       | 26792/100000 [00:12<00:33, 2182.98ex/s]\u001b[A\n",
      " 27%|██▋       | 27013/100000 [00:13<00:36, 2013.50ex/s]\u001b[A\n",
      " 27%|██▋       | 27240/100000 [00:13<00:34, 2083.35ex/s]\u001b[A\n",
      " 27%|██▋       | 27471/100000 [00:13<00:33, 2144.91ex/s]\u001b[A\n",
      " 28%|██▊       | 27702/100000 [00:13<00:33, 2189.93ex/s]\u001b[A\n",
      " 28%|██▊       | 27934/100000 [00:13<00:32, 2227.55ex/s]\u001b[A\n",
      " 28%|██▊       | 28159/100000 [00:13<00:36, 1971.21ex/s]\u001b[A\n",
      " 28%|██▊       | 28388/100000 [00:13<00:34, 2056.42ex/s]\u001b[A\n",
      " 29%|██▊       | 28619/100000 [00:13<00:33, 2126.98ex/s]\u001b[A\n",
      " 29%|██▉       | 28848/100000 [00:13<00:32, 2171.37ex/s]\u001b[A\n",
      " 29%|██▉       | 29069/100000 [00:14<00:42, 1662.98ex/s]\u001b[A\n",
      " 29%|██▉       | 29298/100000 [00:14<00:39, 1811.13ex/s]\u001b[A\n",
      " 30%|██▉       | 29525/100000 [00:14<00:36, 1926.14ex/s]\u001b[A\n",
      " 30%|██▉       | 29753/100000 [00:14<00:34, 2020.37ex/s]\u001b[A\n",
      " 30%|██▉       | 29982/100000 [00:14<00:33, 2094.62ex/s]\u001b[A\n",
      " 30%|███       | 30200/100000 [00:14<00:35, 1955.31ex/s]\u001b[A\n",
      " 30%|███       | 30428/100000 [00:14<00:34, 2041.29ex/s]\u001b[A\n",
      " 31%|███       | 30657/100000 [00:14<00:32, 2110.56ex/s]\u001b[A\n",
      " 31%|███       | 30887/100000 [00:14<00:31, 2162.14ex/s]\u001b[A\n",
      " 31%|███       | 31107/100000 [00:15<00:34, 1996.08ex/s]\u001b[A\n",
      " 31%|███▏      | 31336/100000 [00:15<00:33, 2075.06ex/s]\u001b[A\n",
      " 32%|███▏      | 31565/100000 [00:15<00:32, 2135.60ex/s]\u001b[A\n",
      " 32%|███▏      | 31795/100000 [00:15<00:31, 2182.45ex/s]\u001b[A\n",
      " 32%|███▏      | 32016/100000 [00:15<00:33, 2014.62ex/s]\u001b[A\n",
      " 32%|███▏      | 32242/100000 [00:15<00:32, 2082.32ex/s]\u001b[A\n",
      " 32%|███▏      | 32467/100000 [00:15<00:31, 2128.93ex/s]\u001b[A\n",
      " 33%|███▎      | 32698/100000 [00:15<00:30, 2179.12ex/s]\u001b[A\n",
      " 33%|███▎      | 32929/100000 [00:15<00:30, 2217.08ex/s]\u001b[A\n",
      " 33%|███▎      | 33153/100000 [00:15<00:32, 2044.12ex/s]\u001b[A\n",
      " 33%|███▎      | 33383/100000 [00:16<00:31, 2114.03ex/s]\u001b[A\n",
      " 34%|███▎      | 33613/100000 [00:16<00:30, 2166.71ex/s]\u001b[A\n",
      " 34%|███▍      | 33845/100000 [00:16<00:29, 2210.43ex/s]\u001b[A\n",
      " 34%|███▍      | 34068/100000 [00:16<00:32, 2031.49ex/s]\u001b[A\n",
      " 34%|███▍      | 34298/100000 [00:16<00:31, 2104.03ex/s]\u001b[A\n",
      " 35%|███▍      | 34529/100000 [00:16<00:30, 2160.68ex/s]\u001b[A\n",
      " 35%|███▍      | 34758/100000 [00:16<00:29, 2195.50ex/s]\u001b[A\n",
      " 35%|███▍      | 34990/100000 [00:16<00:29, 2231.53ex/s]\u001b[A\n",
      " 35%|███▌      | 35215/100000 [00:16<00:31, 2045.86ex/s]\u001b[A\n",
      " 35%|███▌      | 35445/100000 [00:17<00:30, 2116.11ex/s]\u001b[A\n",
      " 36%|███▌      | 35676/100000 [00:17<00:29, 2169.27ex/s]\u001b[A\n",
      " 36%|███▌      | 35905/100000 [00:17<00:29, 2202.34ex/s]\u001b[A\n",
      " 36%|███▌      | 36128/100000 [00:17<00:31, 2032.16ex/s]\u001b[A\n",
      " 36%|███▋      | 36356/100000 [00:17<00:30, 2099.61ex/s]\u001b[A\n",
      " 37%|███▋      | 36583/100000 [00:17<00:29, 2146.72ex/s]\u001b[A\n",
      " 37%|███▋      | 36814/100000 [00:17<00:28, 2192.58ex/s]\u001b[A\n",
      " 37%|███▋      | 37036/100000 [00:17<00:31, 2019.38ex/s]\u001b[A\n",
      " 37%|███▋      | 37264/100000 [00:17<00:30, 2090.98ex/s]\u001b[A\n",
      " 37%|███▋      | 37493/100000 [00:18<00:29, 2145.00ex/s]\u001b[A\n",
      " 38%|███▊      | 37715/100000 [00:18<00:28, 2165.79ex/s]\u001b[A\n",
      " 38%|███▊      | 37935/100000 [00:18<00:28, 2174.06ex/s]\u001b[A\n",
      " 38%|███▊      | 38154/100000 [00:18<00:31, 1992.40ex/s]\u001b[A\n",
      " 38%|███▊      | 38376/100000 [00:18<00:30, 2053.75ex/s]\u001b[A\n",
      " 39%|███▊      | 38595/100000 [00:18<00:29, 2090.52ex/s]\u001b[A\n",
      " 39%|███▉      | 38814/100000 [00:18<00:28, 2117.70ex/s]\u001b[A\n",
      " 39%|███▉      | 39028/100000 [00:18<00:31, 1963.37ex/s]\u001b[A\n",
      " 39%|███▉      | 39251/100000 [00:18<00:29, 2037.06ex/s]\u001b[A\n",
      " 39%|███▉      | 39475/100000 [00:18<00:28, 2094.26ex/s]\u001b[A\n",
      " 40%|███▉      | 39701/100000 [00:19<00:28, 2141.15ex/s]\u001b[A\n",
      " 40%|███▉      | 39928/100000 [00:19<00:27, 2177.20ex/s]\u001b[A\n",
      " 40%|████      | 40148/100000 [00:19<00:29, 2003.46ex/s]\u001b[A\n",
      " 40%|████      | 40374/100000 [00:19<00:28, 2073.79ex/s]\u001b[A\n",
      " 41%|████      | 40585/100000 [00:19<00:28, 2081.33ex/s]\u001b[A\n",
      " 41%|████      | 40811/100000 [00:19<00:27, 2131.06ex/s]\u001b[A\n",
      " 41%|████      | 41026/100000 [00:19<00:29, 1991.75ex/s]\u001b[A\n",
      " 41%|████▏     | 41255/100000 [00:19<00:28, 2073.49ex/s]\u001b[A\n",
      " 41%|████▏     | 41477/100000 [00:19<00:27, 2114.32ex/s]\u001b[A\n",
      " 42%|████▏     | 41699/100000 [00:20<00:27, 2144.40ex/s]\u001b[A\n",
      " 42%|████▏     | 41915/100000 [00:20<00:27, 2143.53ex/s]\u001b[A\n",
      " 42%|████▏     | 42131/100000 [00:20<00:29, 1935.03ex/s]\u001b[A\n",
      " 42%|████▏     | 42344/100000 [00:20<00:29, 1986.46ex/s]\u001b[A\n",
      " 43%|████▎     | 42552/100000 [00:20<00:28, 2010.26ex/s]\u001b[A\n",
      " 43%|████▎     | 42762/100000 [00:20<00:28, 2035.44ex/s]\u001b[A\n",
      " 43%|████▎     | 42973/100000 [00:20<00:27, 2057.07ex/s]\u001b[A\n",
      " 43%|████▎     | 43181/100000 [00:20<00:30, 1857.16ex/s]\u001b[A\n",
      " 43%|████▎     | 43398/100000 [00:20<00:29, 1939.64ex/s]\u001b[A\n",
      " 44%|████▎     | 43610/100000 [00:21<00:28, 1987.02ex/s]\u001b[A\n",
      " 44%|████▍     | 43828/100000 [00:21<00:27, 2040.80ex/s]\u001b[A\n",
      " 44%|████▍     | 44035/100000 [00:21<00:29, 1874.28ex/s]\u001b[A\n",
      " 44%|████▍     | 44243/100000 [00:21<00:28, 1930.25ex/s]\u001b[A\n",
      " 44%|████▍     | 44463/100000 [00:21<00:27, 2005.73ex/s]\u001b[A\n",
      " 45%|████▍     | 44683/100000 [00:21<00:26, 2059.75ex/s]\u001b[A\n",
      " 45%|████▍     | 44904/100000 [00:21<00:26, 2101.03ex/s]\u001b[A\n",
      " 45%|████▌     | 45116/100000 [00:21<00:28, 1921.04ex/s]\u001b[A\n",
      " 45%|████▌     | 45341/100000 [00:21<00:27, 2009.78ex/s]\u001b[A\n",
      " 46%|████▌     | 45556/100000 [00:21<00:26, 2048.63ex/s]\u001b[A\n",
      " 46%|████▌     | 45784/100000 [00:22<00:25, 2114.76ex/s]\u001b[A\n",
      " 46%|████▌     | 46000/100000 [00:22<00:27, 1977.39ex/s]\u001b[A\n",
      " 46%|████▌     | 46227/100000 [00:22<00:26, 2058.66ex/s]\u001b[A\n",
      " 46%|████▋     | 46458/100000 [00:22<00:25, 2127.86ex/s]\u001b[A\n",
      " 47%|████▋     | 46689/100000 [00:22<00:24, 2179.97ex/s]\u001b[A\n",
      " 47%|████▋     | 46919/100000 [00:22<00:23, 2213.68ex/s]\u001b[A\n",
      " 47%|████▋     | 47142/100000 [00:22<00:26, 2031.85ex/s]\u001b[A\n",
      " 47%|████▋     | 47371/100000 [00:22<00:25, 2101.81ex/s]\u001b[A\n",
      " 48%|████▊     | 47604/100000 [00:22<00:24, 2164.03ex/s]\u001b[A\n",
      " 48%|████▊     | 47838/100000 [00:23<00:23, 2212.15ex/s]\u001b[A\n",
      " 48%|████▊     | 48062/100000 [00:23<00:25, 2032.03ex/s]\u001b[A\n",
      " 48%|████▊     | 48293/100000 [00:23<00:24, 2106.41ex/s]\u001b[A\n",
      " 49%|████▊     | 48524/100000 [00:23<00:23, 2162.64ex/s]\u001b[A\n",
      " 49%|████▉     | 48756/100000 [00:23<00:23, 2206.00ex/s]\u001b[A\n",
      " 49%|████▉     | 48988/100000 [00:23<00:22, 2238.72ex/s]\u001b[A\n",
      " 49%|████▉     | 49214/100000 [00:23<00:24, 2055.84ex/s]\u001b[A\n",
      " 49%|████▉     | 49445/100000 [00:23<00:23, 2125.75ex/s]\u001b[A\n",
      " 50%|████▉     | 49671/100000 [00:23<00:23, 2162.45ex/s]\u001b[A\n",
      " 50%|████▉     | 49902/100000 [00:23<00:22, 2203.49ex/s]\u001b[A\n",
      " 50%|█████     | 50125/100000 [00:24<00:24, 2008.31ex/s]\u001b[A\n",
      " 50%|█████     | 50353/100000 [00:24<00:23, 2081.54ex/s]\u001b[A\n",
      " 51%|█████     | 50586/100000 [00:24<00:22, 2150.63ex/s]\u001b[A\n",
      " 51%|█████     | 50820/100000 [00:24<00:22, 2204.05ex/s]\u001b[A\n",
      " 51%|█████     | 51043/100000 [00:24<00:23, 2043.06ex/s]\u001b[A\n",
      " 51%|█████▏    | 51274/100000 [00:24<00:23, 2116.54ex/s]\u001b[A\n",
      " 52%|█████▏    | 51508/100000 [00:24<00:22, 2177.57ex/s]\u001b[A\n",
      " 52%|█████▏    | 51739/100000 [00:24<00:21, 2213.95ex/s]\u001b[A\n",
      " 52%|█████▏    | 51966/100000 [00:24<00:21, 2228.48ex/s]\u001b[A\n",
      " 52%|█████▏    | 52191/100000 [00:25<00:23, 2037.10ex/s]\u001b[A\n",
      " 52%|█████▏    | 52418/100000 [00:25<00:22, 2100.55ex/s]\u001b[A\n",
      " 53%|█████▎    | 52647/100000 [00:25<00:21, 2152.90ex/s]\u001b[A\n",
      " 53%|█████▎    | 52871/100000 [00:25<00:21, 2177.01ex/s]\u001b[A\n",
      " 53%|█████▎    | 53091/100000 [00:25<00:23, 2010.17ex/s]\u001b[A\n",
      " 53%|█████▎    | 53321/100000 [00:25<00:22, 2088.72ex/s]\u001b[A\n",
      " 54%|█████▎    | 53552/100000 [00:25<00:21, 2149.44ex/s]\u001b[A\n",
      " 54%|█████▍    | 53784/100000 [00:25<00:21, 2196.92ex/s]\u001b[A\n",
      " 54%|█████▍    | 54006/100000 [00:25<00:22, 2033.19ex/s]\u001b[A\n",
      " 54%|█████▍    | 54235/100000 [00:26<00:21, 2103.09ex/s]\u001b[A\n",
      " 54%|█████▍    | 54466/100000 [00:26<00:21, 2160.57ex/s]\u001b[A\n",
      " 55%|█████▍    | 54697/100000 [00:26<00:20, 2201.64ex/s]\u001b[A\n",
      " 55%|█████▍    | 54928/100000 [00:26<00:20, 2232.86ex/s]\u001b[A\n",
      " 55%|█████▌    | 55153/100000 [00:26<00:21, 2053.84ex/s]\u001b[A\n",
      " 55%|█████▌    | 55383/100000 [00:26<00:21, 2121.71ex/s]\u001b[A\n",
      " 56%|█████▌    | 55613/100000 [00:26<00:20, 2170.68ex/s]\u001b[A\n",
      " 56%|█████▌    | 55844/100000 [00:26<00:19, 2208.17ex/s]\u001b[A\n",
      " 56%|█████▌    | 56067/100000 [00:26<00:22, 1937.89ex/s]\u001b[A\n",
      " 56%|█████▋    | 56296/100000 [00:27<00:21, 2030.76ex/s]\u001b[A\n",
      " 57%|█████▋    | 56527/100000 [00:27<00:20, 2106.18ex/s]\u001b[A\n",
      " 57%|█████▋    | 56758/100000 [00:27<00:19, 2163.27ex/s]\u001b[A\n",
      " 57%|█████▋    | 56990/100000 [00:27<00:19, 2206.62ex/s]\u001b[A\n",
      " 57%|█████▋    | 57214/100000 [00:27<00:21, 2032.22ex/s]\u001b[A\n",
      " 57%|█████▋    | 57443/100000 [00:27<00:20, 2101.83ex/s]\u001b[A\n",
      " 58%|█████▊    | 57673/100000 [00:27<00:19, 2156.52ex/s]\u001b[A\n",
      " 58%|█████▊    | 57904/100000 [00:27<00:19, 2198.34ex/s]\u001b[A\n",
      " 58%|█████▊    | 58127/100000 [00:27<00:20, 2028.39ex/s]\u001b[A\n",
      " 58%|█████▊    | 58351/100000 [00:27<00:19, 2086.44ex/s]\u001b[A\n",
      " 59%|█████▊    | 58578/100000 [00:28<00:19, 2138.29ex/s]\u001b[A\n",
      " 59%|█████▉    | 58808/100000 [00:28<00:18, 2184.80ex/s]\u001b[A\n",
      " 59%|█████▉    | 59029/100000 [00:28<00:20, 2022.70ex/s]\u001b[A\n",
      " 59%|█████▉    | 59253/100000 [00:28<00:19, 2081.67ex/s]\u001b[A\n",
      " 59%|█████▉    | 59480/100000 [00:28<00:18, 2133.60ex/s]\u001b[A\n",
      " 60%|█████▉    | 59709/100000 [00:28<00:18, 2177.75ex/s]\u001b[A\n",
      " 60%|█████▉    | 59938/100000 [00:28<00:18, 2209.68ex/s]\u001b[A\n",
      " 60%|██████    | 60161/100000 [00:28<00:19, 2017.90ex/s]\u001b[A\n",
      " 60%|██████    | 60386/100000 [00:28<00:19, 2081.76ex/s]\u001b[A\n",
      " 61%|██████    | 60615/100000 [00:29<00:18, 2140.13ex/s]\u001b[A\n",
      " 61%|██████    | 60843/100000 [00:29<00:17, 2178.82ex/s]\u001b[A\n",
      " 61%|██████    | 61063/100000 [00:29<00:19, 2017.34ex/s]\u001b[A\n",
      " 61%|██████▏   | 61289/100000 [00:29<00:18, 2082.35ex/s]\u001b[A\n",
      " 62%|██████▏   | 61518/100000 [00:29<00:17, 2139.53ex/s]\u001b[A\n",
      " 62%|██████▏   | 61749/100000 [00:29<00:17, 2186.04ex/s]\u001b[A\n",
      " 62%|██████▏   | 61980/100000 [00:29<00:17, 2221.50ex/s]\u001b[A\n",
      " 62%|██████▏   | 62204/100000 [00:29<00:18, 2031.80ex/s]\u001b[A\n",
      " 62%|██████▏   | 62431/100000 [00:29<00:17, 2096.50ex/s]\u001b[A\n",
      " 63%|██████▎   | 62664/100000 [00:30<00:17, 2160.16ex/s]\u001b[A\n",
      " 63%|██████▎   | 62895/100000 [00:30<00:16, 2203.16ex/s]\u001b[A\n",
      " 63%|██████▎   | 63118/100000 [00:30<00:18, 2033.56ex/s]\u001b[A\n",
      " 63%|██████▎   | 63340/100000 [00:30<00:17, 2084.06ex/s]\u001b[A\n",
      " 64%|██████▎   | 63552/100000 [00:30<00:17, 2072.04ex/s]\u001b[A\n",
      " 64%|██████▍   | 63774/100000 [00:30<00:17, 2113.06ex/s]\u001b[A\n",
      " 64%|██████▍   | 63990/100000 [00:30<00:16, 2126.56ex/s]\u001b[A\n",
      " 64%|██████▍   | 64204/100000 [00:30<00:18, 1917.97ex/s]\u001b[A\n",
      " 64%|██████▍   | 64422/100000 [00:30<00:17, 1988.21ex/s]\u001b[A\n",
      " 65%|██████▍   | 64646/100000 [00:30<00:17, 2058.88ex/s]\u001b[A\n",
      " 65%|██████▍   | 64867/100000 [00:31<00:16, 2101.88ex/s]\u001b[A\n",
      " 65%|██████▌   | 65080/100000 [00:31<00:17, 1945.91ex/s]\u001b[A\n",
      " 65%|██████▌   | 65297/100000 [00:31<00:17, 2006.65ex/s]\u001b[A\n",
      " 66%|██████▌   | 65514/100000 [00:31<00:16, 2052.11ex/s]\u001b[A\n",
      " 66%|██████▌   | 65732/100000 [00:31<00:16, 2086.70ex/s]\u001b[A\n",
      " 66%|██████▌   | 65962/100000 [00:31<00:15, 2147.68ex/s]\u001b[A\n",
      " 66%|██████▌   | 66179/100000 [00:31<00:16, 1990.53ex/s]\u001b[A\n",
      " 66%|██████▋   | 66408/100000 [00:31<00:16, 2073.17ex/s]\u001b[A\n",
      " 67%|██████▋   | 66640/100000 [00:31<00:15, 2142.55ex/s]\u001b[A\n",
      " 67%|██████▋   | 66870/100000 [00:32<00:15, 2185.83ex/s]\u001b[A\n",
      " 67%|██████▋   | 67091/100000 [00:32<00:16, 2003.92ex/s]\u001b[A\n",
      " 67%|██████▋   | 67315/100000 [00:32<00:15, 2066.99ex/s]\u001b[A\n",
      " 68%|██████▊   | 67541/100000 [00:32<00:15, 2121.37ex/s]\u001b[A\n",
      " 68%|██████▊   | 67769/100000 [00:32<00:14, 2164.96ex/s]\u001b[A\n",
      " 68%|██████▊   | 67989/100000 [00:32<00:14, 2174.47ex/s]\u001b[A\n",
      " 68%|██████▊   | 68208/100000 [00:32<00:15, 1990.86ex/s]\u001b[A\n",
      " 68%|██████▊   | 68433/100000 [00:32<00:15, 2061.22ex/s]\u001b[A\n",
      " 69%|██████▊   | 68655/100000 [00:32<00:14, 2103.64ex/s]\u001b[A\n",
      " 69%|██████▉   | 68882/100000 [00:33<00:14, 2149.35ex/s]\u001b[A\n",
      " 69%|██████▉   | 69099/100000 [00:33<00:15, 1969.39ex/s]\u001b[A\n",
      " 69%|██████▉   | 69320/100000 [00:33<00:15, 2034.87ex/s]\u001b[A\n",
      " 70%|██████▉   | 69546/100000 [00:33<00:14, 2096.23ex/s]\u001b[A\n",
      " 70%|██████▉   | 69777/100000 [00:33<00:14, 2155.83ex/s]\u001b[A\n",
      " 70%|███████   | 70000/100000 [00:33<00:14, 2000.31ex/s]\u001b[A\n",
      " 70%|███████   | 70220/100000 [00:33<00:14, 2053.94ex/s]\u001b[A\n",
      " 70%|███████   | 70439/100000 [00:33<00:14, 2091.88ex/s]\u001b[A\n",
      " 71%|███████   | 70667/100000 [00:33<00:13, 2145.93ex/s]\u001b[A\n",
      " 71%|███████   | 70888/100000 [00:33<00:13, 2164.45ex/s]\u001b[A\n",
      " 71%|███████   | 71106/100000 [00:34<00:14, 1980.24ex/s]\u001b[A\n",
      " 71%|███████▏  | 71327/100000 [00:34<00:14, 2042.98ex/s]\u001b[A\n",
      " 72%|███████▏  | 71550/100000 [00:34<00:13, 2094.84ex/s]\u001b[A\n",
      " 72%|███████▏  | 71772/100000 [00:34<00:13, 2129.94ex/s]\u001b[A\n",
      " 72%|███████▏  | 71997/100000 [00:34<00:12, 2164.89ex/s]\u001b[A\n",
      " 72%|███████▏  | 72215/100000 [00:34<00:14, 1979.22ex/s]\u001b[A\n",
      " 72%|███████▏  | 72440/100000 [00:34<00:13, 2051.82ex/s]\u001b[A\n",
      " 73%|███████▎  | 72667/100000 [00:34<00:12, 2111.59ex/s]\u001b[A\n",
      " 73%|███████▎  | 72890/100000 [00:34<00:12, 2145.25ex/s]\u001b[A\n",
      " 73%|███████▎  | 73107/100000 [00:35<00:13, 1981.36ex/s]\u001b[A\n",
      " 73%|███████▎  | 73336/100000 [00:35<00:12, 2065.07ex/s]\u001b[A\n",
      " 74%|███████▎  | 73566/100000 [00:35<00:12, 2129.16ex/s]\u001b[A\n",
      " 74%|███████▍  | 73792/100000 [00:35<00:12, 2166.45ex/s]\u001b[A\n",
      " 74%|███████▍  | 74011/100000 [00:35<00:13, 1998.04ex/s]\u001b[A\n",
      " 74%|███████▍  | 74226/100000 [00:35<00:12, 2039.79ex/s]\u001b[A\n",
      " 74%|███████▍  | 74450/100000 [00:35<00:12, 2095.26ex/s]\u001b[A\n",
      " 75%|███████▍  | 74682/100000 [00:35<00:11, 2158.06ex/s]\u001b[A\n",
      " 75%|███████▍  | 74913/100000 [00:35<00:11, 2202.07ex/s]\u001b[A\n",
      " 75%|███████▌  | 75135/100000 [00:36<00:12, 2024.26ex/s]\u001b[A\n",
      " 75%|███████▌  | 75365/100000 [00:36<00:11, 2098.60ex/s]\u001b[A\n",
      " 76%|███████▌  | 75595/100000 [00:36<00:11, 2155.10ex/s]\u001b[A\n",
      " 76%|███████▌  | 75826/100000 [00:36<00:10, 2198.36ex/s]\u001b[A\n",
      " 76%|███████▌  | 76048/100000 [00:36<00:11, 2031.43ex/s]\u001b[A\n",
      " 76%|███████▋  | 76277/100000 [00:36<00:11, 2100.73ex/s]\u001b[A\n",
      " 77%|███████▋  | 76508/100000 [00:36<00:10, 2157.59ex/s]\u001b[A\n",
      " 77%|███████▋  | 76737/100000 [00:36<00:10, 2193.66ex/s]\u001b[A\n",
      " 77%|███████▋  | 76966/100000 [00:36<00:10, 2215.89ex/s]\u001b[A\n",
      " 77%|███████▋  | 77189/100000 [00:37<00:11, 2032.97ex/s]\u001b[A\n",
      " 77%|███████▋  | 77420/100000 [00:37<00:10, 2108.14ex/s]\u001b[A\n",
      " 78%|███████▊  | 77651/100000 [00:37<00:10, 2163.11ex/s]\u001b[A\n",
      " 78%|███████▊  | 77883/100000 [00:37<00:10, 2206.62ex/s]\u001b[A\n",
      " 78%|███████▊  | 78106/100000 [00:37<00:10, 2015.18ex/s]\u001b[A\n",
      " 78%|███████▊  | 78335/100000 [00:37<00:10, 2090.30ex/s]\u001b[A\n",
      " 79%|███████▊  | 78563/100000 [00:37<00:10, 2143.25ex/s]\u001b[A\n",
      " 79%|███████▉  | 78794/100000 [00:37<00:09, 2188.50ex/s]\u001b[A\n",
      " 79%|███████▉  | 79016/100000 [00:37<00:10, 2027.17ex/s]\u001b[A\n",
      " 79%|███████▉  | 79244/100000 [00:37<00:09, 2095.11ex/s]\u001b[A\n",
      " 79%|███████▉  | 79473/100000 [00:38<00:09, 2149.40ex/s]\u001b[A\n",
      " 80%|███████▉  | 79691/100000 [00:38<00:09, 2157.05ex/s]\u001b[A\n",
      " 80%|███████▉  | 79922/100000 [00:38<00:09, 2201.18ex/s]\u001b[A\n",
      " 80%|████████  | 80144/100000 [00:38<00:09, 2012.46ex/s]\u001b[A\n",
      " 80%|████████  | 80369/100000 [00:38<00:09, 2076.46ex/s]\u001b[A\n",
      " 81%|████████  | 80599/100000 [00:38<00:09, 2139.65ex/s]\u001b[A\n",
      " 81%|████████  | 80816/100000 [00:38<00:08, 2147.60ex/s]\u001b[A\n",
      " 81%|████████  | 81033/100000 [00:38<00:09, 1986.35ex/s]\u001b[A\n",
      " 81%|████████▏ | 81255/100000 [00:38<00:09, 2050.73ex/s]\u001b[A\n",
      " 81%|████████▏ | 81481/100000 [00:39<00:08, 2109.10ex/s]\u001b[A\n",
      " 82%|████████▏ | 81707/100000 [00:39<00:08, 2151.48ex/s]\u001b[A\n",
      " 82%|████████▏ | 81937/100000 [00:39<00:08, 2194.54ex/s]\u001b[A\n",
      " 82%|████████▏ | 82158/100000 [00:39<00:08, 2006.40ex/s]\u001b[A\n",
      " 82%|████████▏ | 82387/100000 [00:39<00:08, 2083.63ex/s]\u001b[A\n",
      " 83%|████████▎ | 82617/100000 [00:39<00:08, 2144.52ex/s]\u001b[A\n",
      " 83%|████████▎ | 82848/100000 [00:39<00:07, 2191.43ex/s]\u001b[A\n",
      " 83%|████████▎ | 83070/100000 [00:39<00:08, 2027.95ex/s]\u001b[A\n",
      " 83%|████████▎ | 83299/100000 [00:39<00:07, 2099.28ex/s]\u001b[A\n",
      " 84%|████████▎ | 83528/100000 [00:39<00:07, 2151.66ex/s]\u001b[A\n",
      " 84%|████████▍ | 83759/100000 [00:40<00:07, 2196.94ex/s]\u001b[A\n",
      " 84%|████████▍ | 83989/100000 [00:40<00:07, 2225.02ex/s]\u001b[A\n",
      " 84%|████████▍ | 84213/100000 [00:40<00:07, 2041.80ex/s]\u001b[A\n",
      " 84%|████████▍ | 84429/100000 [00:40<00:07, 2073.71ex/s]\u001b[A\n",
      " 85%|████████▍ | 84640/100000 [00:40<00:07, 2081.09ex/s]\u001b[A\n",
      " 85%|████████▍ | 84851/100000 [00:40<00:07, 2005.69ex/s]\u001b[A\n",
      " 85%|████████▌ | 85054/100000 [00:40<00:08, 1829.67ex/s]\u001b[A\n",
      " 85%|████████▌ | 85258/100000 [00:40<00:07, 1884.08ex/s]\u001b[A\n",
      " 85%|████████▌ | 85474/100000 [00:40<00:07, 1957.98ex/s]\u001b[A\n",
      " 86%|████████▌ | 85690/100000 [00:41<00:07, 2012.81ex/s]\u001b[A\n",
      " 86%|████████▌ | 85907/100000 [00:41<00:06, 2057.04ex/s]\u001b[A\n",
      " 86%|████████▌ | 86115/100000 [00:41<00:07, 1879.92ex/s]\u001b[A\n",
      " 86%|████████▋ | 86340/100000 [00:41<00:06, 1979.86ex/s]\u001b[A\n",
      " 87%|████████▋ | 86567/100000 [00:41<00:06, 2059.73ex/s]\u001b[A\n",
      " 87%|████████▋ | 86793/100000 [00:41<00:06, 2116.66ex/s]\u001b[A\n",
      " 87%|████████▋ | 87008/100000 [00:41<00:06, 1942.68ex/s]\u001b[A\n",
      " 87%|████████▋ | 87232/100000 [00:41<00:06, 2024.16ex/s]\u001b[A\n",
      " 87%|████████▋ | 87461/100000 [00:41<00:05, 2096.72ex/s]\u001b[A\n",
      " 88%|████████▊ | 87690/100000 [00:42<00:05, 2151.41ex/s]\u001b[A\n",
      " 88%|████████▊ | 87917/100000 [00:42<00:05, 2185.41ex/s]\u001b[A\n",
      " 88%|████████▊ | 88138/100000 [00:42<00:05, 2002.41ex/s]\u001b[A\n",
      " 88%|████████▊ | 88364/100000 [00:42<00:05, 2071.75ex/s]\u001b[A\n",
      " 89%|████████▊ | 88595/100000 [00:42<00:05, 2136.76ex/s]\u001b[A\n",
      " 89%|████████▉ | 88824/100000 [00:42<00:05, 2178.86ex/s]\u001b[A\n",
      " 89%|████████▉ | 89044/100000 [00:42<00:06, 1662.99ex/s]\u001b[A\n",
      " 89%|████████▉ | 89272/100000 [00:42<00:05, 1810.22ex/s]\u001b[A\n",
      " 90%|████████▉ | 89504/100000 [00:42<00:05, 1939.92ex/s]\u001b[A\n",
      " 90%|████████▉ | 89736/100000 [00:43<00:05, 2039.58ex/s]\u001b[A\n",
      " 90%|████████▉ | 89968/100000 [00:43<00:04, 2114.80ex/s]\u001b[A\n",
      " 90%|█████████ | 90188/100000 [00:43<00:04, 1976.30ex/s]\u001b[A\n",
      " 90%|█████████ | 90418/100000 [00:43<00:04, 2063.29ex/s]\u001b[A\n",
      " 91%|█████████ | 90649/100000 [00:43<00:04, 2129.79ex/s]\u001b[A\n",
      " 91%|█████████ | 90880/100000 [00:43<00:04, 2180.86ex/s]\u001b[A\n",
      " 91%|█████████ | 91102/100000 [00:43<00:04, 2018.94ex/s]\u001b[A\n",
      " 91%|█████████▏| 91331/100000 [00:43<00:04, 2091.50ex/s]\u001b[A\n",
      " 92%|█████████▏| 91560/100000 [00:43<00:03, 2147.22ex/s]\u001b[A\n",
      " 92%|█████████▏| 91790/100000 [00:44<00:03, 2190.04ex/s]\u001b[A\n",
      " 92%|█████████▏| 92012/100000 [00:44<00:03, 2020.13ex/s]\u001b[A\n",
      " 92%|█████████▏| 92240/100000 [00:44<00:03, 2089.80ex/s]\u001b[A\n",
      " 92%|█████████▏| 92470/100000 [00:44<00:03, 2147.76ex/s]\u001b[A\n",
      " 93%|█████████▎| 92700/100000 [00:44<00:03, 2189.90ex/s]\u001b[A\n",
      " 93%|█████████▎| 92931/100000 [00:44<00:03, 2224.01ex/s]\u001b[A\n",
      " 93%|█████████▎| 93155/100000 [00:44<00:03, 2044.65ex/s]\u001b[A\n",
      " 93%|█████████▎| 93381/100000 [00:44<00:03, 2103.78ex/s]\u001b[A\n",
      " 94%|█████████▎| 93602/100000 [00:44<00:02, 2133.27ex/s]\u001b[A\n",
      " 94%|█████████▍| 93821/100000 [00:45<00:02, 2147.45ex/s]\u001b[A\n",
      " 94%|█████████▍| 94038/100000 [00:45<00:03, 1970.38ex/s]\u001b[A\n",
      " 94%|█████████▍| 94264/100000 [00:45<00:02, 2049.35ex/s]\u001b[A\n",
      " 94%|█████████▍| 94490/100000 [00:45<00:02, 2108.53ex/s]\u001b[A\n",
      " 95%|█████████▍| 94704/100000 [00:45<00:02, 2108.07ex/s]\u001b[A\n",
      " 95%|█████████▍| 94927/100000 [00:45<00:02, 2142.75ex/s]\u001b[A\n",
      " 95%|█████████▌| 95143/100000 [00:45<00:02, 1958.42ex/s]\u001b[A\n",
      " 95%|█████████▌| 95357/100000 [00:45<00:02, 2008.15ex/s]\u001b[A\n",
      " 96%|█████████▌| 95580/100000 [00:45<00:02, 2069.92ex/s]\u001b[A\n",
      " 96%|█████████▌| 95806/100000 [00:45<00:01, 2124.02ex/s]\u001b[A\n",
      " 96%|█████████▌| 96021/100000 [00:46<00:02, 1975.61ex/s]\u001b[A\n",
      " 96%|█████████▌| 96247/100000 [00:46<00:01, 2054.22ex/s]\u001b[A\n",
      " 96%|█████████▋| 96473/100000 [00:46<00:01, 2110.60ex/s]\u001b[A\n",
      " 97%|█████████▋| 96700/100000 [00:46<00:01, 2154.05ex/s]\u001b[A\n",
      " 97%|█████████▋| 96931/100000 [00:46<00:01, 2197.90ex/s]\u001b[A\n",
      " 97%|█████████▋| 97153/100000 [00:46<00:01, 2021.49ex/s]\u001b[A\n",
      " 97%|█████████▋| 97373/100000 [00:46<00:01, 2069.26ex/s]\u001b[A\n",
      " 98%|█████████▊| 97603/100000 [00:46<00:01, 2133.97ex/s]\u001b[A\n",
      " 98%|█████████▊| 97831/100000 [00:46<00:00, 2175.54ex/s]\u001b[A\n",
      " 98%|█████████▊| 98051/100000 [00:47<00:00, 2009.09ex/s]\u001b[A\n",
      " 98%|█████████▊| 98273/100000 [00:47<00:00, 2067.45ex/s]\u001b[A\n",
      " 98%|█████████▊| 98496/100000 [00:47<00:00, 2113.50ex/s]\u001b[A\n",
      " 99%|█████████▊| 98724/100000 [00:47<00:00, 2161.23ex/s]\u001b[A\n",
      " 99%|█████████▉| 98948/100000 [00:47<00:00, 2183.03ex/s]\u001b[A\n",
      " 99%|█████████▉| 99168/100000 [00:47<00:00, 1999.78ex/s]\u001b[A\n",
      " 99%|█████████▉| 99396/100000 [00:47<00:00, 2076.98ex/s]\u001b[A\n",
      "100%|█████████▉| 99627/100000 [00:47<00:00, 2142.21ex/s]\u001b[A\n",
      "100%|██████████| 100000/100000 [00:47<00:00, 2083.37ex/s][A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?ba/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:12,  7.68ba/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:12,  7.85ba/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:12,  7.84ba/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:12,  7.76ba/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:12,  7.81ba/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:11,  7.85ba/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:11,  7.83ba/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:01<00:11,  7.70ba/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:01<00:11,  7.68ba/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:11,  7.70ba/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:01<00:11,  7.71ba/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:11,  7.76ba/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:01<00:11,  7.79ba/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:10,  7.83ba/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:01<00:10,  7.80ba/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:02<00:10,  7.79ba/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:02<00:10,  7.83ba/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:02<00:10,  7.83ba/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:02<00:10,  7.44ba/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:02<00:10,  7.43ba/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:02<00:10,  7.44ba/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:02<00:10,  7.35ba/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:03<00:10,  7.46ba/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:03<00:10,  7.52ba/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:03<00:09,  7.54ba/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:03<00:09,  7.59ba/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:03<00:09,  7.66ba/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:03<00:09,  7.74ba/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:03<00:09,  7.79ba/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:03<00:08,  7.83ba/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:04<00:08,  7.86ba/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:04<00:08,  7.86ba/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:04<00:08,  7.90ba/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:04<00:08,  7.90ba/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:04<00:08,  7.92ba/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:04<00:08,  7.93ba/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:04<00:07,  7.91ba/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:04<00:07,  7.92ba/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:05<00:07,  7.91ba/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:05<00:07,  7.91ba/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:05<00:07,  7.92ba/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:05<00:07,  7.94ba/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:05<00:07,  7.93ba/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:05<00:07,  7.95ba/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:05<00:06,  7.94ba/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:05<00:06,  7.92ba/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:06<00:06,  7.92ba/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:06<00:06,  7.91ba/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:06<00:06,  7.88ba/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:06<00:06,  7.91ba/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:06<00:06,  7.93ba/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:06<00:06,  7.92ba/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:06<00:06,  7.82ba/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:06<00:05,  7.79ba/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:07<00:05,  7.74ba/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:07<00:06,  6.72ba/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:07<00:06,  7.02ba/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:07<00:05,  7.23ba/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:07<00:05,  7.36ba/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:07<00:05,  7.49ba/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:07<00:05,  7.59ba/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:08<00:04,  7.70ba/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:08<00:04,  7.71ba/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:08<00:04,  7.75ba/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:08<00:04,  7.77ba/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:08<00:04,  7.83ba/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:08<00:04,  7.82ba/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:08<00:04,  7.86ba/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:08<00:03,  7.87ba/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:09<00:03,  7.89ba/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:09<00:03,  7.92ba/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:09<00:03,  7.94ba/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:09<00:03,  7.92ba/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:09<00:03,  7.93ba/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:09<00:03,  7.85ba/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:09<00:03,  7.84ba/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:09<00:02,  7.83ba/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:10<00:02,  7.83ba/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:10<00:02,  7.82ba/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:10<00:02,  7.69ba/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:10<00:02,  7.67ba/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:10<00:02,  7.65ba/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:10<00:02,  7.60ba/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:10<00:02,  7.60ba/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:10<00:02,  7.49ba/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:11<00:01,  7.57ba/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:11<00:01,  7.57ba/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:11<00:01,  7.60ba/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:11<00:01,  7.64ba/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:11<00:01,  7.65ba/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:11<00:01,  7.70ba/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:11<00:01,  7.63ba/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [00:12<00:00,  7.65ba/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:12<00:00,  7.70ba/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:12<00:00,  7.69ba/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:12<00:00,  7.63ba/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:12<00:00,  7.57ba/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:12<00:00,  7.54ba/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:12<00:00,  7.58ba/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.71ba/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?ba/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:13,  7.41ba/s]\u001b[A\n",
      "  2%|▏         | 2/100 [00:00<00:13,  7.51ba/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:12,  7.69ba/s]\u001b[A\n",
      "  4%|▍         | 4/100 [00:00<00:12,  7.68ba/s]\u001b[A\n",
      "  5%|▌         | 5/100 [00:00<00:12,  7.78ba/s]\u001b[A\n",
      "  6%|▌         | 6/100 [00:00<00:11,  7.84ba/s]\u001b[A\n",
      "  7%|▋         | 7/100 [00:00<00:11,  7.86ba/s]\u001b[A\n",
      "  8%|▊         | 8/100 [00:01<00:11,  7.87ba/s]\u001b[A\n",
      "  9%|▉         | 9/100 [00:01<00:11,  7.91ba/s]\u001b[A\n",
      " 10%|█         | 10/100 [00:01<00:11,  7.92ba/s]\u001b[A\n",
      " 11%|█         | 11/100 [00:01<00:11,  7.93ba/s]\u001b[A\n",
      " 12%|█▏        | 12/100 [00:01<00:11,  7.93ba/s]\u001b[A\n",
      " 13%|█▎        | 13/100 [00:01<00:10,  7.94ba/s]\u001b[A\n",
      " 14%|█▍        | 14/100 [00:01<00:10,  7.94ba/s]\u001b[A\n",
      " 15%|█▌        | 15/100 [00:01<00:10,  7.94ba/s]\u001b[A\n",
      " 16%|█▌        | 16/100 [00:02<00:10,  7.95ba/s]\u001b[A\n",
      " 17%|█▋        | 17/100 [00:02<00:10,  7.95ba/s]\u001b[A\n",
      " 18%|█▊        | 18/100 [00:02<00:10,  7.96ba/s]\u001b[A\n",
      " 19%|█▉        | 19/100 [00:02<00:10,  7.94ba/s]\u001b[A\n",
      " 20%|██        | 20/100 [00:02<00:10,  7.94ba/s]\u001b[A\n",
      " 21%|██        | 21/100 [00:02<00:09,  7.97ba/s]\u001b[A\n",
      " 22%|██▏       | 22/100 [00:02<00:09,  7.97ba/s]\u001b[A\n",
      " 23%|██▎       | 23/100 [00:02<00:09,  7.96ba/s]\u001b[A\n",
      " 24%|██▍       | 24/100 [00:03<00:09,  7.98ba/s]\u001b[A\n",
      " 25%|██▌       | 25/100 [00:03<00:09,  7.98ba/s]\u001b[A\n",
      " 26%|██▌       | 26/100 [00:03<00:09,  8.00ba/s]\u001b[A\n",
      " 27%|██▋       | 27/100 [00:03<00:09,  8.00ba/s]\u001b[A\n",
      " 28%|██▊       | 28/100 [00:03<00:08,  8.00ba/s]\u001b[A\n",
      " 29%|██▉       | 29/100 [00:03<00:08,  7.99ba/s]\u001b[A\n",
      " 30%|███       | 30/100 [00:03<00:08,  7.99ba/s]\u001b[A\n",
      " 31%|███       | 31/100 [00:03<00:08,  7.96ba/s]\u001b[A\n",
      " 32%|███▏      | 32/100 [00:04<00:08,  7.96ba/s]\u001b[A\n",
      " 33%|███▎      | 33/100 [00:04<00:08,  7.95ba/s]\u001b[A\n",
      " 34%|███▍      | 34/100 [00:04<00:08,  7.89ba/s]\u001b[A\n",
      " 35%|███▌      | 35/100 [00:04<00:08,  7.87ba/s]\u001b[A\n",
      " 36%|███▌      | 36/100 [00:04<00:08,  7.88ba/s]\u001b[A\n",
      " 37%|███▋      | 37/100 [00:04<00:07,  7.90ba/s]\u001b[A\n",
      " 38%|███▊      | 38/100 [00:04<00:07,  7.92ba/s]\u001b[A\n",
      " 39%|███▉      | 39/100 [00:04<00:07,  7.94ba/s]\u001b[A\n",
      " 40%|████      | 40/100 [00:05<00:07,  7.95ba/s]\u001b[A\n",
      " 41%|████      | 41/100 [00:05<00:07,  7.96ba/s]\u001b[A\n",
      " 42%|████▏     | 42/100 [00:05<00:07,  7.97ba/s]\u001b[A\n",
      " 43%|████▎     | 43/100 [00:05<00:07,  7.98ba/s]\u001b[A\n",
      " 44%|████▍     | 44/100 [00:05<00:07,  7.98ba/s]\u001b[A\n",
      " 45%|████▌     | 45/100 [00:05<00:06,  7.98ba/s]\u001b[A\n",
      " 46%|████▌     | 46/100 [00:05<00:06,  7.98ba/s]\u001b[A\n",
      " 47%|████▋     | 47/100 [00:05<00:06,  7.97ba/s]\u001b[A\n",
      " 48%|████▊     | 48/100 [00:06<00:06,  7.99ba/s]\u001b[A\n",
      " 49%|████▉     | 49/100 [00:06<00:06,  7.98ba/s]\u001b[A\n",
      " 50%|█████     | 50/100 [00:06<00:06,  8.00ba/s]\u001b[A\n",
      " 51%|█████     | 51/100 [00:06<00:06,  7.99ba/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:06<00:05,  8.00ba/s]\u001b[A\n",
      " 53%|█████▎    | 53/100 [00:06<00:05,  7.99ba/s]\u001b[A\n",
      " 54%|█████▍    | 54/100 [00:06<00:05,  7.99ba/s]\u001b[A\n",
      " 55%|█████▌    | 55/100 [00:06<00:05,  7.98ba/s]\u001b[A\n",
      " 56%|█████▌    | 56/100 [00:07<00:05,  7.97ba/s]\u001b[A\n",
      " 57%|█████▋    | 57/100 [00:07<00:05,  7.96ba/s]\u001b[A\n",
      " 58%|█████▊    | 58/100 [00:07<00:05,  7.97ba/s]\u001b[A\n",
      " 59%|█████▉    | 59/100 [00:07<00:05,  7.98ba/s]\u001b[A\n",
      " 60%|██████    | 60/100 [00:07<00:05,  7.94ba/s]\u001b[A\n",
      " 61%|██████    | 61/100 [00:07<00:04,  7.96ba/s]\u001b[A\n",
      " 62%|██████▏   | 62/100 [00:07<00:04,  7.96ba/s]\u001b[A\n",
      " 63%|██████▎   | 63/100 [00:07<00:04,  7.92ba/s]\u001b[A\n",
      " 64%|██████▍   | 64/100 [00:08<00:04,  7.93ba/s]\u001b[A\n",
      " 65%|██████▌   | 65/100 [00:08<00:04,  7.92ba/s]\u001b[A\n",
      " 66%|██████▌   | 66/100 [00:08<00:04,  7.85ba/s]\u001b[A\n",
      " 67%|██████▋   | 67/100 [00:08<00:04,  7.83ba/s]\u001b[A\n",
      " 68%|██████▊   | 68/100 [00:08<00:04,  7.78ba/s]\u001b[A\n",
      " 69%|██████▉   | 69/100 [00:08<00:03,  7.83ba/s]\u001b[A\n",
      " 70%|███████   | 70/100 [00:08<00:03,  7.89ba/s]\u001b[A\n",
      " 71%|███████   | 71/100 [00:08<00:03,  7.89ba/s]\u001b[A\n",
      " 72%|███████▏  | 72/100 [00:09<00:03,  7.93ba/s]\u001b[A\n",
      " 73%|███████▎  | 73/100 [00:09<00:03,  7.94ba/s]\u001b[A\n",
      " 74%|███████▍  | 74/100 [00:09<00:03,  7.97ba/s]\u001b[A\n",
      " 75%|███████▌  | 75/100 [00:09<00:03,  7.84ba/s]\u001b[A\n",
      " 76%|███████▌  | 76/100 [00:09<00:03,  7.68ba/s]\u001b[A\n",
      " 77%|███████▋  | 77/100 [00:09<00:03,  7.57ba/s]\u001b[A\n",
      " 78%|███████▊  | 78/100 [00:09<00:02,  7.54ba/s]\u001b[A\n",
      " 79%|███████▉  | 79/100 [00:10<00:02,  7.50ba/s]\u001b[A\n",
      " 80%|████████  | 80/100 [00:10<00:02,  7.45ba/s]\u001b[A\n",
      " 81%|████████  | 81/100 [00:10<00:02,  7.41ba/s]\u001b[A\n",
      " 82%|████████▏ | 82/100 [00:10<00:02,  7.36ba/s]\u001b[A\n",
      " 83%|████████▎ | 83/100 [00:10<00:02,  7.34ba/s]\u001b[A\n",
      " 84%|████████▍ | 84/100 [00:10<00:02,  7.40ba/s]\u001b[A\n",
      " 85%|████████▌ | 85/100 [00:10<00:02,  7.38ba/s]\u001b[A\n",
      " 86%|████████▌ | 86/100 [00:10<00:01,  7.44ba/s]\u001b[A\n",
      " 87%|████████▋ | 87/100 [00:11<00:01,  7.48ba/s]\u001b[A\n",
      " 88%|████████▊ | 88/100 [00:11<00:01,  7.60ba/s]\u001b[A\n",
      " 89%|████████▉ | 89/100 [00:11<00:01,  7.66ba/s]\u001b[A\n",
      " 90%|█████████ | 90/100 [00:11<00:01,  7.77ba/s]\u001b[A\n",
      " 91%|█████████ | 91/100 [00:11<00:01,  7.82ba/s]\u001b[A\n",
      " 92%|█████████▏| 92/100 [00:11<00:01,  7.88ba/s]\u001b[A\n",
      " 93%|█████████▎| 93/100 [00:11<00:00,  7.89ba/s]\u001b[A\n",
      " 94%|█████████▍| 94/100 [00:11<00:00,  7.92ba/s]\u001b[A\n",
      " 95%|█████████▌| 95/100 [00:12<00:00,  7.94ba/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:12<00:00,  7.95ba/s]\u001b[A\n",
      " 97%|█████████▋| 97/100 [00:12<00:00,  7.92ba/s]\u001b[A\n",
      " 98%|█████████▊| 98/100 [00:12<00:00,  7.94ba/s]\u001b[A\n",
      " 99%|█████████▉| 99/100 [00:12<00:00,  7.95ba/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.86ba/s]\u001b[A\n",
      "Some weights of the model checkpoint at armheb/DNA_bert_6 were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at armheb/DNA_bert_6 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n",
      "/opt/conda/envs/cdna_one/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 60000\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 93700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9370' max='93700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9370/93700 44:59 < 6:44:57, 3.47 it/s, Epoch 9/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Rocauc 0 Roc Auc</th>\n",
       "      <th>Rocauc 1 Roc Auc</th>\n",
       "      <th>Pr Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.549800</td>\n",
       "      <td>0.272664</td>\n",
       "      <td>0.881933</td>\n",
       "      <td>0.887477</td>\n",
       "      <td>0.931324</td>\n",
       "      <td>0.847573</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.959529</td>\n",
       "      <td>0.957961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.270766</td>\n",
       "      <td>0.899533</td>\n",
       "      <td>0.895558</td>\n",
       "      <td>0.861582</td>\n",
       "      <td>0.932323</td>\n",
       "      <td>0.965365</td>\n",
       "      <td>0.965365</td>\n",
       "      <td>0.963340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.362619</td>\n",
       "      <td>0.875667</td>\n",
       "      <td>0.863079</td>\n",
       "      <td>0.783838</td>\n",
       "      <td>0.960144</td>\n",
       "      <td>0.966762</td>\n",
       "      <td>0.966762</td>\n",
       "      <td>0.964585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.248200</td>\n",
       "      <td>0.264711</td>\n",
       "      <td>0.897800</td>\n",
       "      <td>0.902537</td>\n",
       "      <td>0.946526</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.967552</td>\n",
       "      <td>0.967552</td>\n",
       "      <td>0.965438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.242168</td>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.908064</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.894553</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.965576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>0.254580</td>\n",
       "      <td>0.905867</td>\n",
       "      <td>0.907628</td>\n",
       "      <td>0.925057</td>\n",
       "      <td>0.890844</td>\n",
       "      <td>0.967541</td>\n",
       "      <td>0.967541</td>\n",
       "      <td>0.965352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.209200</td>\n",
       "      <td>0.275993</td>\n",
       "      <td>0.899667</td>\n",
       "      <td>0.904158</td>\n",
       "      <td>0.946660</td>\n",
       "      <td>0.865310</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>0.967489</td>\n",
       "      <td>0.965254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.253712</td>\n",
       "      <td>0.907067</td>\n",
       "      <td>0.907474</td>\n",
       "      <td>0.911588</td>\n",
       "      <td>0.903396</td>\n",
       "      <td>0.967170</td>\n",
       "      <td>0.967170</td>\n",
       "      <td>0.964855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.264419</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>0.894295</td>\n",
       "      <td>0.860248</td>\n",
       "      <td>0.931149</td>\n",
       "      <td>0.966285</td>\n",
       "      <td>0.966285</td>\n",
       "      <td>0.963932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.169700</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.903133</td>\n",
       "      <td>0.904339</td>\n",
       "      <td>0.915855</td>\n",
       "      <td>0.893108</td>\n",
       "      <td>0.965349</td>\n",
       "      <td>0.965349</td>\n",
       "      <td>0.962900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-937\n",
      "Configuration saved in outputs/checkpoint-937/config.json\n",
      "Model weights saved in outputs/checkpoint-937/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-937/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-937/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-1874\n",
      "Configuration saved in outputs/checkpoint-1874/config.json\n",
      "Model weights saved in outputs/checkpoint-1874/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1874/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1874/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-2811\n",
      "Configuration saved in outputs/checkpoint-2811/config.json\n",
      "Model weights saved in outputs/checkpoint-2811/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-2811/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-2811/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-3748\n",
      "Configuration saved in outputs/checkpoint-3748/config.json\n",
      "Model weights saved in outputs/checkpoint-3748/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-3748/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-3748/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-4685\n",
      "Configuration saved in outputs/checkpoint-4685/config.json\n",
      "Model weights saved in outputs/checkpoint-4685/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-4685/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-4685/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-5622\n",
      "Configuration saved in outputs/checkpoint-5622/config.json\n",
      "Model weights saved in outputs/checkpoint-5622/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-5622/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-5622/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-6559\n",
      "Configuration saved in outputs/checkpoint-6559/config.json\n",
      "Model weights saved in outputs/checkpoint-6559/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-6559/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-6559/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-7496\n",
      "Configuration saved in outputs/checkpoint-7496/config.json\n",
      "Model weights saved in outputs/checkpoint-7496/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-7496/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-7496/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-8433\n",
      "Configuration saved in outputs/checkpoint-8433/config.json\n",
      "Model weights saved in outputs/checkpoint-8433/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-8433/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-8433/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 15000\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to outputs/checkpoint-9370\n",
      "Configuration saved in outputs/checkpoint-9370/config.json\n",
      "Model weights saved in outputs/checkpoint-9370/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-9370/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-9370/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from outputs/checkpoint-4685 (score: 0.24216803908348083).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25000\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "early stopping required metric_for_best_model, but did not find eval_loss so early stopping is disabled\n",
      "100%|██████████| 1/1 [47:08<00:00, 2828.90s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import random, randrange\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import torch\n",
    "\n",
    "def compute_metrics_binary(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    prediction_scores = torch.nn.functional.softmax(\n",
    "        torch.from_numpy(logits).double(), dim=-1).numpy() \n",
    "    # predictions = np.argmax(logits, axis=-1) #equivalent\n",
    "    predictions = np.argmax(prediction_scores, axis=-1)\n",
    "    return binary_metrics.compute(\n",
    "        predictions=predictions, \n",
    "        references=labels, \n",
    "        prediction_scores=prediction_scores[:,1] #taking only prediction percentage for the label 1\n",
    "    )\n",
    "    \n",
    "#TODO human_ensembl_regulatory dataset multilabel metrics\n",
    "def compute_metrics_multi(eval_preds):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for dataset_name, dataset_version in tqdm(DATASETS):\n",
    "    labels = sorted([x.stem for x in (benchmark_root / dataset_name / 'train').iterdir()])\n",
    "\n",
    "    tmp_dict = {}\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        for nlabel, label in enumerate(labels):\n",
    "            for f in (benchmark_root / dataset_name / split / label).glob('*.txt'):\n",
    "                txt = f.read_text()\n",
    "                if not DATASET_THINING or DATASET_THINING==1:\n",
    "                    tmp_dict[f\"{label} {f.stem}\"] = (split, nlabel, txt)\n",
    "                elif random() < DATASET_THINING:\n",
    "                    tmp_dict[f\"{label} {f.stem}\"] = (split, nlabel, txt)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(tmp_dict).T.rename(columns = {0: \"dset\", 1: \"cat\", 2: \"seq\"})\n",
    "\n",
    "    ds = Dataset.from_pandas(df)\n",
    "\n",
    "    tok_ds = ds.map(tok_func, batched=False, remove_columns=['__index_level_0__', 'seq'])\n",
    "    tok_ds = tok_ds.rename_columns({'cat':'labels'})\n",
    "\n",
    "    dds = DatasetDict({\n",
    "        'train': tok_ds.filter(lambda x: x[\"dset\"] == \"train\").remove_columns('dset'),\n",
    "        'test':  tok_ds.filter(lambda x: x[\"dset\"] == \"test\").remove_columns('dset')\n",
    "    })\n",
    "    train_valid_split = dds['train'].train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "    dds['train']=train_valid_split['train']\n",
    "    dds['valid']=train_valid_split['test']\n",
    "\n",
    "    compute_metrics = compute_metrics_binary if len(labels) == 2 else compute_metrics_multi\n",
    "\n",
    "    for _ in range(RUNS):\n",
    "        model_cls = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(labels))\n",
    "        if(RANDOMIZE_WEIGHTS):\n",
    "            # model_cls.init_weights() #Alternative\n",
    "            model_cls = AutoModelForSequenceClassification.from_config(model_cls.config)   \n",
    "            if(RESIZE_EMBEDDINGS):\n",
    "                model_cls.resize_token_embeddings(len(tokenizer))\n",
    "            \n",
    "        args = get_trainargs()\n",
    "        \n",
    "        trainer = Trainer(model_cls, args, train_dataset=dds['train'], eval_dataset=dds['valid'],\n",
    "                          tokenizer=tokenizer, compute_metrics=compute_metrics, \n",
    "                          callbacks=callbacks)\n",
    "        trainer.train()\n",
    "        trainer.evaluate(dds['test'], metric_key_prefix='test')\n",
    "        training_log = get_log_from_history(trainer.state.log_history, dataset_name=dataset_name)\n",
    "        outputs.append(training_log)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fckdKKcoYbFR"
   },
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Q-d5WgMLTR-E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_auroc_macro</th>\n",
       "      <th>test_auroc_weighted</th>\n",
       "      <th>test_pr_auc</th>\n",
       "      <th>min_valid_loss_epoch</th>\n",
       "      <th>min_valid_loss_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>demo_coding_vs_intergenomic_seqs</td>\n",
       "      <td>0.90152</td>\n",
       "      <td>0.902826</td>\n",
       "      <td>0.260564</td>\n",
       "      <td>0.89101</td>\n",
       "      <td>0.91496</td>\n",
       "      <td>0.963782</td>\n",
       "      <td>0.963782</td>\n",
       "      <td>0.962473</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'eval_loss': 0.24216803908348083, 'eval_accur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            dataset  test_acc   test_f1  test_loss  \\\n",
       "0  demo_coding_vs_intergenomic_seqs   0.90152  0.902826   0.260564   \n",
       "\n",
       "   test_precision  test_recall  test_auroc_macro  test_auroc_weighted  \\\n",
       "0         0.89101      0.91496          0.963782             0.963782   \n",
       "\n",
       "   test_pr_auc  min_valid_loss_epoch  \\\n",
       "0     0.962473                   5.0   \n",
       "\n",
       "                                  min_valid_loss_log  \n",
       "0  {'eval_loss': 0.24216803908348083, 'eval_accur...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_df = pd.DataFrame(outputs)\n",
    "outputs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QXq1XNgFVKSn"
   },
   "outputs": [],
   "source": [
    "# outputs_df.groupby('dataset').agg({'accuracy' : ['mean', 'sem'], 'f1' : ['mean','sem'], 'train_runtime': ['mean', 'sem']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bP6TQPmYYlrb"
   },
   "outputs": [],
   "source": [
    "# saving outputs to csv file\n",
    "outputs_df.to_csv(OUTPUT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Metrics_on_genomic_benchmarks_short_inputs_colab.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:cdna_one]",
   "language": "python",
   "name": "conda-env-cdna_one-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01d30f8e4fde43fc8a3e4593d3932d47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "240183ed0048432e8f953293ea24bdce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "628aa13a3c8140be876e937c87d111be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1389c9d504e41b3bdc51a8805cfee5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cb813c47be474313bb9bdbec8327ddaf",
       "IPY_MODEL_d33afcc4a33442d090d29ff1284e49ec",
       "IPY_MODEL_dd67380f41b548cc8882b31219ab36de"
      ],
      "layout": "IPY_MODEL_628aa13a3c8140be876e937c87d111be"
     }
    },
    "b59de534cb5b4d4486c6033c8f7bb4c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c04acfbcab1549e891f2320534af0400": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb813c47be474313bb9bdbec8327ddaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b59de534cb5b4d4486c6033c8f7bb4c2",
      "placeholder": "​",
      "style": "IPY_MODEL_e3f54f15415a4a27bb77a7c06410db57",
      "value": "100%"
     }
    },
    "d33afcc4a33442d090d29ff1284e49ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01d30f8e4fde43fc8a3e4593d3932d47",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_240183ed0048432e8f953293ea24bdce",
      "value": 1
     }
    },
    "dd67380f41b548cc8882b31219ab36de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e9ca594da9214565bf101c528d74fc3d",
      "placeholder": "​",
      "style": "IPY_MODEL_c04acfbcab1549e891f2320534af0400",
      "value": " 1/1 [00:00&lt;00:00, 28.86it/s]"
     }
    },
    "e3f54f15415a4a27bb77a7c06410db57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9ca594da9214565bf101c528d74fc3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
