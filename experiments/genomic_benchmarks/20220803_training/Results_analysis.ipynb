{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b82ef03-e21d-4eab-a6aa-56a7f37dd513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "csv_files = list((Path().glob('*.csv')))\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    split = str(file).split('_')\n",
    "    architecture = split[0]\n",
    "    tokenizer = split[-2]\n",
    "    random_weights = False\n",
    "    if('RANDOM' in split):\n",
    "        random_weights = True\n",
    "        \n",
    "    df.insert(0, 'random_weights',random_weights)\n",
    "    df.insert(0, 'tokenizer',tokenizer)\n",
    "    df.insert(0, 'architecture',architecture)\n",
    "    \n",
    "    df['file_name'] = file\n",
    "    dfs.append(df)\n",
    "    # print(df.head())\n",
    "\n",
    "main_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d1c4c4a-ca4f-4969-a47e-6d6afadf5d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>random_weights</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_auroc_macro</th>\n",
       "      <th>test_auroc_weighted</th>\n",
       "      <th>test_pr_auc</th>\n",
       "      <th>min_valid_loss_epoch</th>\n",
       "      <th>min_valid_loss_log</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>demo_coding_vs_intergenomic_seqs</td>\n",
       "      <td>0.901200</td>\n",
       "      <td>0.901492</td>\n",
       "      <td>0.243529</td>\n",
       "      <td>0.898839</td>\n",
       "      <td>0.904160</td>\n",
       "      <td>0.963793</td>\n",
       "      <td>0.963793</td>\n",
       "      <td>0.961481</td>\n",
       "      <td>3.0</td>\n",
       "      <td>{'eval_loss': 0.23157711327075958, 'eval_accur...</td>\n",
       "      <td>DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>demo_human_or_worm</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>0.954912</td>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.948394</td>\n",
       "      <td>0.961520</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.991370</td>\n",
       "      <td>0.991745</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'eval_loss': 0.12817776203155518, 'eval_accur...</td>\n",
       "      <td>DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>human_enhancers_cohn</td>\n",
       "      <td>0.730282</td>\n",
       "      <td>0.729191</td>\n",
       "      <td>0.541984</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>0.726252</td>\n",
       "      <td>0.804544</td>\n",
       "      <td>0.804544</td>\n",
       "      <td>0.799972</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'eval_loss': 0.5247995257377625, 'eval_accura...</td>\n",
       "      <td>DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>human_enhancers_ensembl</td>\n",
       "      <td>0.812851</td>\n",
       "      <td>0.810848</td>\n",
       "      <td>0.415992</td>\n",
       "      <td>0.819621</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.893935</td>\n",
       "      <td>0.893935</td>\n",
       "      <td>0.895679</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'eval_loss': 0.41570723056793213, 'eval_accur...</td>\n",
       "      <td>DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>human_nontata_promoters</td>\n",
       "      <td>0.835510</td>\n",
       "      <td>0.824225</td>\n",
       "      <td>0.482745</td>\n",
       "      <td>0.984459</td>\n",
       "      <td>0.708850</td>\n",
       "      <td>0.924087</td>\n",
       "      <td>0.924087</td>\n",
       "      <td>0.950049</td>\n",
       "      <td>5.0</td>\n",
       "      <td>{'eval_loss': 0.21176204085350037, 'eval_accur...</td>\n",
       "      <td>DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  architecture         tokenizer  random_weights  \\\n",
       "0      DEBERTA  DNABERTtokenizer            True   \n",
       "1      DEBERTA  DNABERTtokenizer            True   \n",
       "2      DEBERTA  DNABERTtokenizer            True   \n",
       "3      DEBERTA  DNABERTtokenizer            True   \n",
       "4      DEBERTA  DNABERTtokenizer            True   \n",
       "\n",
       "                            dataset  test_acc   test_f1  test_loss  \\\n",
       "0  demo_coding_vs_intergenomic_seqs  0.901200  0.901492   0.243529   \n",
       "1                demo_human_or_worm  0.954600  0.954912   0.121361   \n",
       "2              human_enhancers_cohn  0.730282  0.729191   0.541984   \n",
       "3           human_enhancers_ensembl  0.812851  0.810848   0.415992   \n",
       "4           human_nontata_promoters  0.835510  0.824225   0.482745   \n",
       "\n",
       "   test_precision  test_recall  test_auroc_macro  test_auroc_weighted  \\\n",
       "0        0.898839     0.904160          0.963793             0.963793   \n",
       "1        0.948394     0.961520          0.991370             0.991370   \n",
       "2        0.732153     0.726252          0.804544             0.804544   \n",
       "3        0.819621     0.802260          0.893935             0.893935   \n",
       "4        0.984459     0.708850          0.924087             0.924087   \n",
       "\n",
       "   test_pr_auc  min_valid_loss_epoch  \\\n",
       "0     0.961481                   3.0   \n",
       "1     0.991745                   2.0   \n",
       "2     0.799972                   4.0   \n",
       "3     0.895679                   5.0   \n",
       "4     0.950049                   5.0   \n",
       "\n",
       "                                  min_valid_loss_log  \\\n",
       "0  {'eval_loss': 0.23157711327075958, 'eval_accur...   \n",
       "1  {'eval_loss': 0.12817776203155518, 'eval_accur...   \n",
       "2  {'eval_loss': 0.5247995257377625, 'eval_accura...   \n",
       "3  {'eval_loss': 0.41570723056793213, 'eval_accur...   \n",
       "4  {'eval_loss': 0.21176204085350037, 'eval_accur...   \n",
       "\n",
       "                                     file_name  \n",
       "0  DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv  \n",
       "1  DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv  \n",
       "2  DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv  \n",
       "3  DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv  \n",
       "4  DEBERTA_RANDOM_DNABERTtokenizer_metrics.csv  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa0418e2-4577-457e-b6be-89aafef707dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architecture</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>random_weights</th>\n",
       "      <th>dataset</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_auroc_macro</th>\n",
       "      <th>test_auroc_weighted</th>\n",
       "      <th>test_pr_auc</th>\n",
       "      <th>min_valid_loss_epoch</th>\n",
       "      <th>min_valid_loss_log</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>DNABERT</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>demo_coding_vs_intergenomic_seqs</td>\n",
       "      <td>0.924600</td>\n",
       "      <td>0.925936</td>\n",
       "      <td>0.190143</td>\n",
       "      <td>0.909814</td>\n",
       "      <td>0.942640</td>\n",
       "      <td>0.978707</td>\n",
       "      <td>0.978707</td>\n",
       "      <td>0.978504</td>\n",
       "      <td>6.0</td>\n",
       "      <td>{'eval_loss': 0.17874711751937866, 'eval_accur...</td>\n",
       "      <td>DNABERT_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DNABERT</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>demo_human_or_worm</td>\n",
       "      <td>0.965800</td>\n",
       "      <td>0.965733</td>\n",
       "      <td>0.088603</td>\n",
       "      <td>0.967633</td>\n",
       "      <td>0.963840</td>\n",
       "      <td>0.995246</td>\n",
       "      <td>0.995246</td>\n",
       "      <td>0.995429</td>\n",
       "      <td>4.0</td>\n",
       "      <td>{'eval_loss': 0.09043285995721817, 'eval_accur...</td>\n",
       "      <td>DNABERT_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>DNABERT</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>human_enhancers_cohn</td>\n",
       "      <td>0.741940</td>\n",
       "      <td>0.749476</td>\n",
       "      <td>0.515198</td>\n",
       "      <td>0.728211</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>0.818516</td>\n",
       "      <td>7.0</td>\n",
       "      <td>{'eval_loss': 0.5061564445495605, 'eval_accura...</td>\n",
       "      <td>DNABERT_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>DNABERT</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>human_enhancers_ensembl</td>\n",
       "      <td>0.866096</td>\n",
       "      <td>0.865867</td>\n",
       "      <td>0.314362</td>\n",
       "      <td>0.867354</td>\n",
       "      <td>0.864385</td>\n",
       "      <td>0.941497</td>\n",
       "      <td>0.941497</td>\n",
       "      <td>0.942554</td>\n",
       "      <td>8.0</td>\n",
       "      <td>{'eval_loss': 0.312751442193985, 'eval_accurac...</td>\n",
       "      <td>DNABERT_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>DEBERTA</td>\n",
       "      <td>Kmer8tokenizer</td>\n",
       "      <td>True</td>\n",
       "      <td>human_nontata_promoters</td>\n",
       "      <td>0.892517</td>\n",
       "      <td>0.894353</td>\n",
       "      <td>0.279150</td>\n",
       "      <td>0.961179</td>\n",
       "      <td>0.836216</td>\n",
       "      <td>0.958166</td>\n",
       "      <td>0.958166</td>\n",
       "      <td>0.970961</td>\n",
       "      <td>2.0</td>\n",
       "      <td>{'eval_loss': 0.17499646544456482, 'eval_accur...</td>\n",
       "      <td>DEBERTA_RANDOM_Kmer8tokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>DNABERT</td>\n",
       "      <td>DNABERTtokenizer</td>\n",
       "      <td>False</td>\n",
       "      <td>human_ocr_ensembl</td>\n",
       "      <td>0.768511</td>\n",
       "      <td>0.762344</td>\n",
       "      <td>0.502806</td>\n",
       "      <td>0.783210</td>\n",
       "      <td>0.742561</td>\n",
       "      <td>0.850755</td>\n",
       "      <td>0.850755</td>\n",
       "      <td>0.839602</td>\n",
       "      <td>8.0</td>\n",
       "      <td>{'eval_loss': 0.49689358472824097, 'eval_accur...</td>\n",
       "      <td>DNABERT_DNABERTtokenizer_metrics.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   architecture         tokenizer  random_weights  \\\n",
       "60      DNABERT  DNABERTtokenizer           False   \n",
       "61      DNABERT  DNABERTtokenizer           False   \n",
       "62      DNABERT  DNABERTtokenizer           False   \n",
       "63      DNABERT  DNABERTtokenizer           False   \n",
       "52      DEBERTA    Kmer8tokenizer            True   \n",
       "65      DNABERT  DNABERTtokenizer           False   \n",
       "\n",
       "                             dataset  test_acc   test_f1  test_loss  \\\n",
       "60  demo_coding_vs_intergenomic_seqs  0.924600  0.925936   0.190143   \n",
       "61                demo_human_or_worm  0.965800  0.965733   0.088603   \n",
       "62              human_enhancers_cohn  0.741940  0.749476   0.515198   \n",
       "63           human_enhancers_ensembl  0.866096  0.865867   0.314362   \n",
       "52           human_nontata_promoters  0.892517  0.894353   0.279150   \n",
       "65                 human_ocr_ensembl  0.768511  0.762344   0.502806   \n",
       "\n",
       "    test_precision  test_recall  test_auroc_macro  test_auroc_weighted  \\\n",
       "60        0.909814     0.942640          0.978707             0.978707   \n",
       "61        0.967633     0.963840          0.995246             0.995246   \n",
       "62        0.728211     0.772021          0.828015             0.828015   \n",
       "63        0.867354     0.864385          0.941497             0.941497   \n",
       "52        0.961179     0.836216          0.958166             0.958166   \n",
       "65        0.783210     0.742561          0.850755             0.850755   \n",
       "\n",
       "    test_pr_auc  min_valid_loss_epoch  \\\n",
       "60     0.978504                   6.0   \n",
       "61     0.995429                   4.0   \n",
       "62     0.818516                   7.0   \n",
       "63     0.942554                   8.0   \n",
       "52     0.970961                   2.0   \n",
       "65     0.839602                   8.0   \n",
       "\n",
       "                                   min_valid_loss_log  \\\n",
       "60  {'eval_loss': 0.17874711751937866, 'eval_accur...   \n",
       "61  {'eval_loss': 0.09043285995721817, 'eval_accur...   \n",
       "62  {'eval_loss': 0.5061564445495605, 'eval_accura...   \n",
       "63  {'eval_loss': 0.312751442193985, 'eval_accurac...   \n",
       "52  {'eval_loss': 0.17499646544456482, 'eval_accur...   \n",
       "65  {'eval_loss': 0.49689358472824097, 'eval_accur...   \n",
       "\n",
       "                                    file_name  \n",
       "60       DNABERT_DNABERTtokenizer_metrics.csv  \n",
       "61       DNABERT_DNABERTtokenizer_metrics.csv  \n",
       "62       DNABERT_DNABERTtokenizer_metrics.csv  \n",
       "63       DNABERT_DNABERTtokenizer_metrics.csv  \n",
       "52  DEBERTA_RANDOM_Kmer8tokenizer_metrics.csv  \n",
       "65       DNABERT_DNABERTtokenizer_metrics.csv  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.iloc[main_df.groupby('dataset')['test_acc'].idxmax()]\n",
    "# main_df.iloc[main_df.groupby(['dataset','tokenizer'])['test_loss'].idxmax()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afb4021-6157-4254-bec6-a949d1eb88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myCudaCondaEnv]",
   "language": "python",
   "name": "conda-env-myCudaCondaEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
