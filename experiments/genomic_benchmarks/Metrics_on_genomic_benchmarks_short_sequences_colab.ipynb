{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vTrn2sqTOGNV"
      },
      "outputs": [],
      "source": [
        "!pip install -qq transformers genomic-benchmarks datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z4cFV03UpD4",
        "outputId": "5dfeb7de-712a-4556-e990-5fd4277a311b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Gyck9b-I6tpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee2e692-7936-4250-9b27-789db827718d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('human_enhancers_ensembl', 0)]\n"
          ]
        }
      ],
      "source": [
        "### Parameters\n",
        "MODEL_NAME = \"davidcechak/DNADebertaK8\"\n",
        "TOKENIZER_NAME = \"armheb/DNA_bert_6\"\n",
        "K = 8\n",
        "STRIDE = 1\n",
        "\n",
        "# if less than 1, only this fraction of each dataset is used\n",
        "DATASET_THINING = 1\n",
        "\n",
        "BENCHMARKS_FOLDER = '/root/.genomic_benchmarks'\n",
        "# BENCHMARKS_FOLDER = '/home/jovyan/.genomic_benchmarks/' (for INFRA HUB)\n",
        "\n",
        "# for long-sequence datasets:\n",
        "# \"Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\"\n",
        "# ('human_enhancers_cohn', 0), ('human_ensembl_regulatory', 0), ('human_ocr_ensembl', 0), ('human_enhancers_ensembl', 0)\n",
        "\n",
        "# short-sequence datasets\n",
        "DATASETS = [('demo_coding_vs_intergenomic_seqs', 0),\n",
        " ('demo_human_or_worm', 0), ('human_nontata_promoters', 0)]\n",
        "\n",
        "# All datasets\n",
        "# DATASETS = [('demo_coding_vs_intergenomic_seqs', 0),\n",
        "#  ('demo_human_or_worm', 0), ('human_enhancers_cohn', 0), ('human_enhancers_ensembl', 0),\n",
        "#  ('human_ensembl_regulatory', 0), ('human_nontata_promoters', 0), ('human_ocr_ensembl', 0)]\n",
        "\n",
        "\n",
        "# if ensemble refuses connection - \"[Errno 104] Connection reset by peer\", use attribute use_cloud_cache=True\n",
        "USE_CLOUD_CACHE = True\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 8e-5\n",
        "EPOCHS = 1\n",
        "RUNS = 1\n",
        "\n",
        "# do not forget to attach drive\n",
        "OUTPUT_PATH = 'drive/MyDrive/genomic_benchmarks/experiment1.csv'\n",
        "\n",
        "print(DATASETS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq7oMV6baan7",
        "outputId": "6aa53001-2ddb-4cbf-ec5d-d296b168bf2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/armheb/DNA_bert_6/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2697389de18c4fe8c3497cea35aaf65130fdd59c3ab64cb6b1c2e0632fefdaf0.3a7e1ca237211e6405270f85616f49989aeee994db35f6593a40c7b5081a50d0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"armheb/DNA_bert_6\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/armheb/DNA_bert_6/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/15e3d5912e269ac69e75ac1395d9e0e89459e621c27699bec6cd7dcafc99ddf6.9c302cdc38e51de70854f17e4dfee5ca24224efcea628e270fc0fe39a5e25238\n",
            "loading file https://huggingface.co/armheb/DNA_bert_6/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/armheb/DNA_bert_6/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/armheb/DNA_bert_6/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/e2a020446c0dadc1a84f9fef73389c94f81827af0a86dde4ec17019aec1b7521.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
            "loading file https://huggingface.co/armheb/DNA_bert_6/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/c9c96b3f09942133fcb191f621eda9caab95b0703c1829a550ef95bbf03361c4.f19de0c372e9b00104464e8b09d5fbbdd67565d0e0af78462fb22d8f5d2c1fe1\n",
            "loading configuration file https://huggingface.co/armheb/DNA_bert_6/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2697389de18c4fe8c3497cea35aaf65130fdd59c3ab64cb6b1c2e0632fefdaf0.3a7e1ca237211e6405270f85616f49989aeee994db35f6593a40c7b5081a50d0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"armheb/DNA_bert_6\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/armheb/DNA_bert_6/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/2697389de18c4fe8c3497cea35aaf65130fdd59c3ab64cb6b1c2e0632fefdaf0.3a7e1ca237211e6405270f85616f49989aeee994db35f6593a40c7b5081a50d0\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"armheb/DNA_bert_6\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_rnn_layer\": 1,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"rnn\": \"lstm\",\n",
            "  \"rnn_dropout\": 0.0,\n",
            "  \"rnn_hidden\": 768,\n",
            "  \"split\": 10,\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 4101\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65536"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from itertools import product\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME)\n",
        "\n",
        "alphabet = ('A', 'C', 'T', 'G')\n",
        "vocab = list(map(''.join, product(alphabet, repeat=K)))\n",
        "\n",
        "tokenizer.add_tokens(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoAktdfUsl1"
      },
      "source": [
        "## Download benchmark datasets and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b1389c9d504e41b3bdc51a8805cfee5e",
            "cb813c47be474313bb9bdbec8327ddaf",
            "d33afcc4a33442d090d29ff1284e49ec",
            "dd67380f41b548cc8882b31219ab36de",
            "628aa13a3c8140be876e937c87d111be",
            "b59de534cb5b4d4486c6033c8f7bb4c2",
            "e3f54f15415a4a27bb77a7c06410db57",
            "01d30f8e4fde43fc8a3e4593d3932d47",
            "240183ed0048432e8f953293ea24bdce",
            "e9ca594da9214565bf101c528d74fc3d",
            "c04acfbcab1549e891f2320534af0400"
          ]
        },
        "id": "I3ZRsNqx7LNa",
        "outputId": "3562075e-a73f-4bc5-c977-f5d761762144"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1389c9d504e41b3bdc51a8805cfee5e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from genomic_benchmarks.loc2seq import download_dataset\n",
        "from genomic_benchmarks.data_check.info import is_downloaded\n",
        "from pathlib import Path\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "for dataset_name, dataset_version in tqdm(DATASETS):\n",
        "    if not is_downloaded(dataset_name):\n",
        "        download_dataset(dataset_name, version=dataset_version, use_cloud_cache=USE_CLOUD_CACHE)\n",
        "\n",
        "benchmark_root = Path(BENCHMARKS_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "aolqScmmYaIs",
        "outputId": "5a706116-b020-47ba-a298-57e5d75080dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [2, 16136, 52241, 65592, 53460, 4930, 7417, 17366, 57162, 19737, 66647, 57679, 21806, 9387, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] ATGGAAAG TGGAAAGA GGAAAGAG GAAAGAGG AAAGAGGC AAGAGGCA AGAGGCAC GAGGCACC AGGCACCA GGCACCAT GCACCATT CACCATTC ACCATTCT [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "def kmers_strideK(s, k=K):\n",
        "    return [s[i:i + k] for i in range(0, len(s), k) if i + k <= len(s)]\n",
        "\n",
        "def kmers_stride1(s, k=K):\n",
        "    return [s[i:i + k] for i in range(0, len(s)-k+1)]\n",
        "\n",
        "if (STRIDE == 1):\n",
        "  kmers = kmers_stride1\n",
        "else:\n",
        "  kmers = kmers_strideK\n",
        "\n",
        "# function used for the actual tokenization\n",
        "def tok_func(x): return tokenizer(\" \".join(kmers(x[\"seq\"])))\n",
        "\n",
        "# example\n",
        "example = tok_func({'seq': 'ATGGAAAGAGGCACCATTCT'})    \n",
        "print(example)\n",
        "tokenizer.decode(example['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cYuLrCnUz-K"
      },
      "source": [
        "## Looping through datasets, fine-tuning the model for each of them, logging metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C7mdPSn-0Pl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import random, randrange\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from datasets import Dataset, DatasetDict, load_metric\n",
        "\n",
        "def compute_metrics_binary(eval_preds):\n",
        "    metric = load_metric(\"glue\", \"mrpc\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "def compute_metrics_multi(eval_preds):\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "outputs = []\n",
        "\n",
        "for dataset_name, dataset_version in tqdm(DATASETS):\n",
        "    \n",
        "\n",
        "    labels = sorted([x.stem for x in (benchmark_root / dataset_name / 'train').iterdir()])\n",
        "\n",
        "    tmp_dict = {}\n",
        "\n",
        "    for split in ['train', 'test']:\n",
        "        for nlabel, label in enumerate(labels):\n",
        "            for f in (benchmark_root / dataset_name / split / label).glob('*.txt'):\n",
        "                txt = f.read_text()\n",
        "                if not DATASET_THINING or DATASET_THINING==1:\n",
        "                    tmp_dict[f\"{label} {f.stem}\"] = (split, nlabel, txt)\n",
        "                elif random() < DATASET_THINING:\n",
        "                    tmp_dict[f\"{label} {f.stem}\"] = (split, nlabel, txt)\n",
        "\n",
        "    df = pd.DataFrame.from_dict(tmp_dict).T.rename(columns = {0: \"dset\", 1: \"cat\", 2: \"seq\"})\n",
        "\n",
        "    ds = Dataset.from_pandas(df)\n",
        "\n",
        "    tok_ds = ds.map(tok_func, batched=False, remove_columns=['__index_level_0__', 'seq'])\n",
        "    tok_ds = tok_ds.rename_columns({'cat':'labels'})\n",
        "\n",
        "    dds = DatasetDict({\n",
        "        'train': tok_ds.filter(lambda x: x[\"dset\"] == \"train\").remove_columns('dset'),\n",
        "        'test':  tok_ds.filter(lambda x: x[\"dset\"] == \"test\").remove_columns('dset')\n",
        "    })\n",
        "\n",
        "    compute_metrics = compute_metrics_binary if len(labels) == 2 else compute_metrics_multi\n",
        "\n",
        "    for _ in range(RUNS):\n",
        "\n",
        "        model_cls = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(labels))\n",
        "\n",
        "        args = TrainingArguments('outputs', learning_rate=LEARNING_RATE, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
        "            evaluation_strategy=\"epoch\", per_device_train_batch_size=BATCH_SIZE, per_device_eval_batch_size=BATCH_SIZE*2,\n",
        "            num_train_epochs=EPOCHS, weight_decay=0.01, save_steps=100000, seed=randrange(1,10001), report_to='none')\n",
        "        \n",
        "        trainer = Trainer(model_cls, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "                          tokenizer=tokenizer, compute_metrics=compute_metrics)\n",
        "        trainer.train()\n",
        "        \n",
        "        max_accuracy = max([x['eval_accuracy'] for x in trainer.state.log_history if 'eval_accuracy' in x])\n",
        "        max_f1 = max([x['eval_f1'] for x in trainer.state.log_history if 'eval_f1' in x]) if len(labels) == 2 else np.nan\n",
        "        train_runtime = max([x['train_runtime'] for x in trainer.state.log_history if 'train_runtime' in x])\n",
        "        \n",
        "        outputs.append((dataset_name, max_accuracy, max_f1, train_runtime))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fckdKKcoYbFR"
      },
      "source": [
        "## Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-d5WgMLTR-E"
      },
      "outputs": [],
      "source": [
        "outputs_df = pd.DataFrame(outputs, columns = ['dataset', 'accuracy', 'f1', 'train_runtime'])\n",
        "outputs_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXq1XNgFVKSn"
      },
      "outputs": [],
      "source": [
        "outputs_df.groupby('dataset').agg({'accuracy' : ['mean', 'sem'], 'f1' : ['mean','sem'], 'train_runtime': ['mean', 'sem']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bP6TQPmYYlrb"
      },
      "outputs": [],
      "source": [
        "# saving outputs to csv file\n",
        "outputs_df.to_csv(OUTPUT_PATH, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c2JPqR6MKxF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Metrics_on_genomic_benchmarks_short_inputs_colab.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1389c9d504e41b3bdc51a8805cfee5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb813c47be474313bb9bdbec8327ddaf",
              "IPY_MODEL_d33afcc4a33442d090d29ff1284e49ec",
              "IPY_MODEL_dd67380f41b548cc8882b31219ab36de"
            ],
            "layout": "IPY_MODEL_628aa13a3c8140be876e937c87d111be"
          }
        },
        "cb813c47be474313bb9bdbec8327ddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b59de534cb5b4d4486c6033c8f7bb4c2",
            "placeholder": "​",
            "style": "IPY_MODEL_e3f54f15415a4a27bb77a7c06410db57",
            "value": "100%"
          }
        },
        "d33afcc4a33442d090d29ff1284e49ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d30f8e4fde43fc8a3e4593d3932d47",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_240183ed0048432e8f953293ea24bdce",
            "value": 1
          }
        },
        "dd67380f41b548cc8882b31219ab36de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ca594da9214565bf101c528d74fc3d",
            "placeholder": "​",
            "style": "IPY_MODEL_c04acfbcab1549e891f2320534af0400",
            "value": " 1/1 [00:00&lt;00:00, 28.86it/s]"
          }
        },
        "628aa13a3c8140be876e937c87d111be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59de534cb5b4d4486c6033c8f7bb4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3f54f15415a4a27bb77a7c06410db57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d30f8e4fde43fc8a3e4593d3932d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240183ed0048432e8f953293ea24bdce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9ca594da9214565bf101c528d74fc3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04acfbcab1549e891f2320534af0400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}