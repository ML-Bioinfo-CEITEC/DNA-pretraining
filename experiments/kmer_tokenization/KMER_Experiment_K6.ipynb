{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dfoAktdfUsl1"
   },
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTrn2sqTOGNV",
    "outputId": "a09deacd-0bc8-471e-92a2-749e8e92379d"
   },
   "outputs": [],
   "source": [
    "#!pip install -qq genomic-benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1lbOBvxVKXPE"
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "\n",
    "# K in K-MERS\n",
    "K = 6\n",
    "# BENCHMARK DATASET\n",
    "BENCHMARK = \"human_nontata_promoters\"\n",
    "# NUMBER OF EPOCHS FOR LM TRAINING\n",
    "LM_EPOCHS = 1\n",
    "# FINE TUNING EPOCHS\n",
    "CLS_EPOCHS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3ZRsNqx7LNa",
    "outputId": "09a26816-661d-401a-d7aa-dffafc4cd72e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1VdUg0Zu8yfLS6QesBXwGz1PIQrTW3Ze4\n",
      "To: /home/jovyan/.genomic_benchmarks/human_nontata_promoters.zip\n",
      "100%|██████████| 11.8M/11.8M [00:00<00:00, 80.5MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jovyan/.genomic_benchmarks/human_nontata_promoters')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from genomic_benchmarks.loc2seq import download_dataset\n",
    "\n",
    "download_dataset(BENCHMARK, version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52,
     "referenced_widgets": [
      "143014fcfd2a4a2b9e2c491bfab7f9ed",
      "8116c3cff4cc418eb6c2fc47a6efb452",
      "257c7591a5164e4fa315cb0517644844",
      "f87e6706919a4501b81ac93ea4eec735",
      "0079fe2fe6cc43a9adc0f99c5b30c84c",
      "0eb46c03dec34c018e07f2667f93368e",
      "a94aa776214f4d59893a812e768cc11e",
      "6e0c348e60c54d4397245ab5fbeddea5",
      "e700c36f519340269f44366380538cba",
      "82577495709c40ea966f0a5667fd7aaa",
      "be092e02e18c436d9d72bf49c06ef50a"
     ]
    },
    "id": "V_ivZJRvSAmm",
    "outputId": "c5634e84-d8e8-4d08-e764-94220c0c1931"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(f\"armheb/DNA_bert_{K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CRUvdPH3UEzk"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dccdbb92ed3d408090a6e765122b591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration simecek--Human_DNA_v0-3127ba11a87ac1a1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None (download: 1.25 GiB, generated: 2.73 GiB, post-processed: Unknown size, total: 3.98 GiB) to /home/jovyan/.cache/huggingface/datasets/simecek___parquet/simecek--Human_DNA_v0-3127ba11a87ac1a1/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcb0a8b965e4d4e9c702a59a650fa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702aaa7794b947e19107035f7d698323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f12382ead2a48e0b7bb405de58980dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a61bfa33af4b7888a8ef942fa26fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f98e78b13cd40a88abb6da1ab5f4875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b60c2fb69b42cbb0be45a58db5a2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dd84b3f8ff4a03a0f54c98bd2b26b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a8629be3d54bc9a964e4d5c0c9a45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/201M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ae6953eec94557a81552d8ec34726c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/jovyan/.cache/huggingface/datasets/simecek___parquet/simecek--Human_DNA_v0-3127ba11a87ac1a1/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950a19ab77ec4b6cbb6c141e1c5c47ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "splitted_datasets = load_dataset(\"simecek/Human_DNA_v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "gyIWkUUEVyVC"
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "tiny_datasets = DatasetDict({'train': splitted_datasets['train'].select(range(50000)),\n",
    "                              'test': splitted_datasets['test'].select(range(5000))\n",
    "                           })\n",
    "\n",
    "splitted_datasets = tiny_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cYuLrCnUz-K"
   },
   "source": [
    "\n",
    "## Training LM - Stride K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6tVPA7OEW74G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Seq'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Seq'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aolqScmmYaIs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATGGAA', 'AGAGGC', 'ACCATT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def kmers(s, k=K):\n",
    "    return [s[i:i + k] for i in range(0, len(s), k) if i + k <= len(s)]\n",
    "\n",
    "def kmers_stride1(s, k=K):\n",
    "    return [s[i:i + k] for i in range(0, len(s)-k+1)]\n",
    "\n",
    "kmers(\"ATGGAAAGAGGCACCATTCT\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UNF23jUvUM92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 675, 2000, 393, 3], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(s, k=K):\n",
    "  seq_split = \" \".join(kmers(s['Seq'], k))\n",
    "  return tokenizer(seq_split)\n",
    "\n",
    "tokenize_function({'Seq':'ACCTGCTGGACGATCATA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "eHb-y37pVQR_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afcc54565934a5182995efddbbbf8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a497dc8419be4111bd0636f35fe28cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5dd15be3e9f4f5294459d74037fc333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d27138fe7794906a5185697c1f9cf59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc027a19b594a60b48d4cccdfddf2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2d7b186fd241cfa1b62e1f6393f387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dafe31bba864d75b9781edade871478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e83970361d34167b7becb47e3416891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1668 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = splitted_datasets.map(tokenize_function, remove_columns='Seq', num_proc=4)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5nBn8_XWXSn9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554388e141e0448cbcb438f07dabd2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abfd62aae1d413f89b667eb3b40dc2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 162850\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 16285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of\n",
    "# max_seq_length.\n",
    "# grabbed from: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
    "\n",
    "def group_texts(examples, max_length=512):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= max_length:\n",
    "        total_length = (total_length // max_length) * max_length\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "chunked_datasets = tokenized_datasets.map(group_texts, batched=True, desc=f\"Grouping texts in chunks of 512\")\n",
    "chunked_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JoT8ufjTYAcF"
   },
   "outputs": [],
   "source": [
    "from transformers import DebertaConfig, DebertaForMaskedLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "model_config = DebertaConfig(vocab_size=len(tokenizer.vocab), max_position_embeddings=512, num_hidden_layers=6)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2)\n",
    "model = DebertaForMaskedLM(config=model_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model',          # output directory to where save model checkpoint\n",
    "    evaluation_strategy=\"epoch\",    \n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,      \n",
    "    num_train_epochs=LM_EPOCHS,            # number of training epochs, feel free to tweak\n",
    "    per_device_train_batch_size=32, # the training batch size, put it as high as your GPU memory fits\n",
    "    gradient_accumulation_steps=2,  # accumulating the gradients before updating the weights\n",
    "    per_device_eval_batch_size=32,  # evaluation batch size\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
    "    save_total_limit=1           # whether you don't have much space so you let only 5 model weights saved in the disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YKncXPQGYpA9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=chunked_datasets['train'],\n",
    "    eval_dataset=chunked_datasets['test'],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "pvq0xoO1ajwa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model_strideK/config.json\n",
      "Model weights saved in model_strideK/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 16285\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='509' max='509' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [509/509 00:46]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in '/home/jovyan' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/simecek/huggingface/aba6d9e21add46208391ebc78cda0560\n",
      "\n",
      "Automatic Comet.ml online logging enabled\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 8.464581489562988,\n",
       " 'eval_runtime': 47.0879,\n",
       " 'eval_samples_per_second': 345.843,\n",
       " 'eval_steps_per_second': 10.81}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model_strideK\")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNS44fZ-dL6t"
   },
   "source": [
    "## Training LM - Stride 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3TbIFrY1dlVa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 675, 2686, 2540, 1956, 3713, 2551, 2000, 3889, 3254, 715, 2845, 3174, 393, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(s, k=K):\n",
    "  seq_split = \" \".join(kmers_stride1(s['Seq'], k))\n",
    "  return tokenizer(seq_split)\n",
    "\n",
    "tokenize_function({'Seq':'ACCTGCTGGACGATCATA'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KFZQMXv4dlVa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6be49d543a24843b7c0bb948164e55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4d7ca923dc4a959c64f169b5ac614e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79f5d45b0d344b39cb10389fa72b29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da79670be38a427a8bddd55c64f9d1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/12500 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dbb7d206b594162ac4e1b0b3082c830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42f4af6afb3c45939c5e9597fade5039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e820bcf0974e19989d4c01579eac79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35315694fc8441e3aaf07b3b0ed73369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1250 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (9997 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = splitted_datasets.map(tokenize_function, remove_columns='Seq', num_proc=4)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "LsqKPSa6dlVa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914b46fa89a6419ab4f39f2b48e68c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df071630b274704b36572a7e290eba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grouping texts in chunks of 512:   0%|          | 0/5 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 976250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 97625\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "# Main data processing function that will concatenate all texts from our dataset and generate chunks of\n",
    "# max_seq_length.\n",
    "# grabbed from: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
    "\n",
    "def group_texts(examples, max_length=512):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= max_length:\n",
    "        total_length = (total_length // max_length) * max_length\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + max_length] for i in range(0, total_length, max_length)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result\n",
    "\n",
    "chunked_datasets = tokenized_datasets.map(group_texts, batched=True, desc=f\"Grouping texts in chunks of 512\")\n",
    "chunked_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "wRWpDQlndlVb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaConfig, DebertaForMaskedLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "model_config = DebertaConfig(vocab_size=len(tokenizer.vocab), max_position_embeddings=512, num_hidden_layers=6)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True, mlm_probability=0.2)\n",
    "model = DebertaForMaskedLM(config=model_config)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model',          # output directory to where save model checkpoint\n",
    "    evaluation_strategy=\"epoch\",    \n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,      \n",
    "    num_train_epochs=LM_EPOCHS,            # number of training epochs, feel free to tweak\n",
    "    per_device_train_batch_size=32, # the training batch size, put it as high as your GPU memory fits\n",
    "    gradient_accumulation_steps=2,  # accumulating the gradients before updating the weights\n",
    "    per_device_eval_batch_size=32,  # evaluation batch size\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,  # whether to load the best model (in terms of loss) at the end of training\n",
    "    save_total_limit=1           # whether you don't have much space so you let only 5 model weights saved in the disk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ME3gWiXXdlVb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/jovyan/my-conda-envs/myEnv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 976250\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 15254\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/simecek/huggingface/aba6d9e21add46208391ebc78cda0560\n",
      "COMET INFO:   Metrics:\n",
      "COMET INFO:     eval_loss               : 8.464581489562988\n",
      "COMET INFO:     eval_runtime            : 47.0879\n",
      "COMET INFO:     eval_samples_per_second : 345.843\n",
      "COMET INFO:     eval_steps_per_second   : 10.81\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Created from : transformers\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     args/_n_gpu                             : 1\n",
      "COMET INFO:     args/_no_sync_in_gradient_accumulation  : True\n",
      "COMET INFO:     args/_setup_devices                     : cuda:0\n",
      "COMET INFO:     args/adafactor                          : False\n",
      "COMET INFO:     args/adam_beta1                         : 0.9\n",
      "COMET INFO:     args/adam_beta2                         : 0.999\n",
      "COMET INFO:     args/adam_epsilon                       : 1e-08\n",
      "COMET INFO:     args/auto_find_batch_size               : False\n",
      "COMET INFO:     args/bf16                               : False\n",
      "COMET INFO:     args/bf16_full_eval                     : False\n",
      "COMET INFO:     args/data_seed                          : None\n",
      "COMET INFO:     args/dataloader_drop_last               : False\n",
      "COMET INFO:     args/dataloader_num_workers             : 0\n",
      "COMET INFO:     args/dataloader_pin_memory              : True\n",
      "COMET INFO:     args/ddp_bucket_cap_mb                  : None\n",
      "COMET INFO:     args/ddp_find_unused_parameters         : None\n",
      "COMET INFO:     args/debug                              : []\n",
      "COMET INFO:     args/deepspeed                          : None\n",
      "COMET INFO:     args/device                             : cuda:0\n",
      "COMET INFO:     args/disable_tqdm                       : False\n",
      "COMET INFO:     args/do_eval                            : True\n",
      "COMET INFO:     args/do_predict                         : False\n",
      "COMET INFO:     args/do_train                           : False\n",
      "COMET INFO:     args/eval_accumulation_steps            : None\n",
      "COMET INFO:     args/eval_batch_size                    : 32\n",
      "COMET INFO:     args/eval_delay                         : 0\n",
      "COMET INFO:     args/eval_steps                         : None\n",
      "COMET INFO:     args/evaluation_strategy                : IntervalStrategy.EPOCH\n",
      "COMET INFO:     args/fp16                               : True\n",
      "COMET INFO:     args/fp16_backend                       : auto\n",
      "COMET INFO:     args/fp16_full_eval                     : False\n",
      "COMET INFO:     args/fp16_opt_level                     : O1\n",
      "COMET INFO:     args/fsdp                               : []\n",
      "COMET INFO:     args/fsdp_min_num_params                : 0\n",
      "COMET INFO:     args/full_determinism                   : False\n",
      "COMET INFO:     args/gradient_accumulation_steps        : 2\n",
      "COMET INFO:     args/gradient_checkpointing             : False\n",
      "COMET INFO:     args/greater_is_better                  : False\n",
      "COMET INFO:     args/group_by_length                    : False\n",
      "COMET INFO:     args/half_precision_backend             : amp\n",
      "COMET INFO:     args/hub_model_id                       : None\n",
      "COMET INFO:     args/hub_private_repo                   : False\n",
      "COMET INFO:     args/hub_strategy                       : HubStrategy.EVERY_SAVE\n",
      "COMET INFO:     args/hub_token                          : None\n",
      "COMET INFO:     args/ignore_data_skip                   : False\n",
      "COMET INFO:     args/include_inputs_for_metrics         : False\n",
      "COMET INFO:     args/label_names                        : None\n",
      "COMET INFO:     args/label_smoothing_factor             : 0.0\n",
      "COMET INFO:     args/learning_rate                      : 5e-05\n",
      "COMET INFO:     args/length_column_name                 : length\n",
      "COMET INFO:     args/load_best_model_at_end             : True\n",
      "COMET INFO:     args/local_process_index                : 0\n",
      "COMET INFO:     args/local_rank                         : -1\n",
      "COMET INFO:     args/log_level                          : -1\n",
      "COMET INFO:     args/log_level_replica                  : -1\n",
      "COMET INFO:     args/log_on_each_node                   : True\n",
      "COMET INFO:     args/logging_dir                        : ./model/runs/Jun21_00-22-58_jupyter-simecek\n",
      "COMET INFO:     args/logging_first_step                 : False\n",
      "COMET INFO:     args/logging_nan_inf_filter             : True\n",
      "COMET INFO:     args/logging_steps                      : 500\n",
      "COMET INFO:     args/logging_strategy                   : IntervalStrategy.STEPS\n",
      "COMET INFO:     args/lr_scheduler_type                  : SchedulerType.LINEAR\n",
      "COMET INFO:     args/max_grad_norm                      : 1.0\n",
      "COMET INFO:     args/max_steps                          : -1\n",
      "COMET INFO:     args/metric_for_best_model              : loss\n",
      "COMET INFO:     args/mp_parameters                      : \n",
      "COMET INFO:     args/n_gpu                              : 1\n",
      "COMET INFO:     args/no_cuda                            : False\n",
      "COMET INFO:     args/num_train_epochs                   : 1\n",
      "COMET INFO:     args/optim                              : OptimizerNames.ADAMW_HF\n",
      "COMET INFO:     args/output_dir                         : ./model\n",
      "COMET INFO:     args/overwrite_output_dir               : True\n",
      "COMET INFO:     args/parallel_mode                      : ParallelMode.NOT_PARALLEL\n",
      "COMET INFO:     args/past_index                         : -1\n",
      "COMET INFO:     args/per_device_eval_batch_size         : 32\n",
      "COMET INFO:     args/per_device_train_batch_size        : 32\n",
      "COMET INFO:     args/per_gpu_eval_batch_size            : None\n",
      "COMET INFO:     args/per_gpu_train_batch_size           : None\n",
      "COMET INFO:     args/place_model_on_device              : True\n",
      "COMET INFO:     args/prediction_loss_only               : False\n",
      "COMET INFO:     args/process_index                      : 0\n",
      "COMET INFO:     args/push_to_hub                        : False\n",
      "COMET INFO:     args/push_to_hub_model_id               : None\n",
      "COMET INFO:     args/push_to_hub_organization           : None\n",
      "COMET INFO:     args/push_to_hub_token                  : None\n",
      "COMET INFO:     args/remove_unused_columns              : True\n",
      "COMET INFO:     args/report_to                          : ['comet_ml']\n",
      "COMET INFO:     args/resume_from_checkpoint             : None\n",
      "COMET INFO:     args/run_name                           : ./model\n",
      "COMET INFO:     args/save_on_each_node                  : False\n",
      "COMET INFO:     args/save_steps                         : 500\n",
      "COMET INFO:     args/save_strategy                      : IntervalStrategy.EPOCH\n",
      "COMET INFO:     args/save_total_limit                   : 1\n",
      "COMET INFO:     args/seed                               : 42\n",
      "COMET INFO:     args/sharded_ddp                        : []\n",
      "COMET INFO:     args/should_log                         : True\n",
      "COMET INFO:     args/should_save                        : True\n",
      "COMET INFO:     args/skip_memory_metrics                : True\n",
      "COMET INFO:     args/tf32                               : None\n",
      "COMET INFO:     args/tpu_metrics_debug                  : False\n",
      "COMET INFO:     args/tpu_num_cores                      : None\n",
      "COMET INFO:     args/train_batch_size                   : 32\n",
      "COMET INFO:     args/use_legacy_prediction_loop         : False\n",
      "COMET INFO:     args/warmup_ratio                       : 0.0\n",
      "COMET INFO:     args/warmup_steps                       : 0\n",
      "COMET INFO:     args/weight_decay                       : 0.0\n",
      "COMET INFO:     args/world_size                         : 1\n",
      "COMET INFO:     args/xpu_backend                        : None\n",
      "COMET INFO:     config/_auto_class                      : None\n",
      "COMET INFO:     config/_name_or_path                    : \n",
      "COMET INFO:     config/add_cross_attention              : False\n",
      "COMET INFO:     config/architectures                    : ['DebertaForMaskedLM']\n",
      "COMET INFO:     config/attention_probs_dropout_prob     : 0.1\n",
      "COMET INFO:     config/attribute_map                    : {}\n",
      "COMET INFO:     config/bad_words_ids                    : None\n",
      "COMET INFO:     config/bos_token_id                     : None\n",
      "COMET INFO:     config/chunk_size_feed_forward          : 0\n",
      "COMET INFO:     config/cross_attention_hidden_size      : None\n",
      "COMET INFO:     config/decoder_start_token_id           : None\n",
      "COMET INFO:     config/diversity_penalty                : 0.0\n",
      "COMET INFO:     config/do_sample                        : False\n",
      "COMET INFO:     config/early_stopping                   : False\n",
      "COMET INFO:     config/encoder_no_repeat_ngram_size     : 0\n",
      "COMET INFO:     config/eos_token_id                     : None\n",
      "COMET INFO:     config/exponential_decay_length_penalty : None\n",
      "COMET INFO:     config/finetuning_task                  : None\n",
      "COMET INFO:     config/forced_bos_token_id              : None\n",
      "COMET INFO:     config/forced_eos_token_id              : None\n",
      "COMET INFO:     config/hidden_act                       : gelu\n",
      "COMET INFO:     config/hidden_dropout_prob              : 0.1\n",
      "COMET INFO:     config/hidden_size                      : 768\n",
      "COMET INFO:     config/id2label                         : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "COMET INFO:     config/initializer_range                : 0.02\n",
      "COMET INFO:     config/intermediate_size                : 3072\n",
      "COMET INFO:     config/is_composition                   : False\n",
      "COMET INFO:     config/is_decoder                       : False\n",
      "COMET INFO:     config/is_encoder_decoder               : False\n",
      "COMET INFO:     config/label2id                         : {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "COMET INFO:     config/layer_norm_eps                   : 1e-07\n",
      "COMET INFO:     config/length_penalty                   : 1.0\n",
      "COMET INFO:     config/max_length                       : 20\n",
      "COMET INFO:     config/max_position_embeddings          : 512\n",
      "COMET INFO:     config/max_relative_positions           : -1\n",
      "COMET INFO:     config/min_length                       : 0\n",
      "COMET INFO:     config/model_type                       : deberta\n",
      "COMET INFO:     config/name_or_path                     : \n",
      "COMET INFO:     config/no_repeat_ngram_size             : 0\n",
      "COMET INFO:     config/num_attention_heads              : 12\n",
      "COMET INFO:     config/num_beam_groups                  : 1\n",
      "COMET INFO:     config/num_beams                        : 1\n",
      "COMET INFO:     config/num_hidden_layers                : 6\n",
      "COMET INFO:     config/num_labels                       : 2\n",
      "COMET INFO:     config/num_return_sequences             : 1\n",
      "COMET INFO:     config/output_attentions                : False\n",
      "COMET INFO:     config/output_hidden_states             : False\n",
      "COMET INFO:     config/output_scores                    : False\n",
      "COMET INFO:     config/pad_token_id                     : 0\n",
      "COMET INFO:     config/pooler_dropout                   : 0\n",
      "COMET INFO:     config/pooler_hidden_act                : gelu\n",
      "COMET INFO:     config/pooler_hidden_size               : 768\n",
      "COMET INFO:     config/pos_att_type                     : None\n",
      "COMET INFO:     config/position_biased_input            : True\n",
      "COMET INFO:     config/prefix                           : None\n",
      "COMET INFO:     config/problem_type                     : None\n",
      "COMET INFO:     config/pruned_heads                     : {}\n",
      "COMET INFO:     config/relative_attention               : False\n",
      "COMET INFO:     config/remove_invalid_values            : False\n",
      "COMET INFO:     config/repetition_penalty               : 1.0\n",
      "COMET INFO:     config/return_dict                      : True\n",
      "COMET INFO:     config/return_dict_in_generate          : False\n",
      "COMET INFO:     config/sep_token_id                     : None\n",
      "COMET INFO:     config/task_specific_params             : None\n",
      "COMET INFO:     config/temperature                      : 1.0\n",
      "COMET INFO:     config/tie_encoder_decoder              : False\n",
      "COMET INFO:     config/tie_word_embeddings              : True\n",
      "COMET INFO:     config/tokenizer_class                  : None\n",
      "COMET INFO:     config/top_k                            : 50\n",
      "COMET INFO:     config/top_p                            : 1.0\n",
      "COMET INFO:     config/torch_dtype                      : float32\n",
      "COMET INFO:     config/torchscript                      : False\n",
      "COMET INFO:     config/transformers_version             : None\n",
      "COMET INFO:     config/type_vocab_size                  : 0\n",
      "COMET INFO:     config/typical_p                        : 1.0\n",
      "COMET INFO:     config/use_bfloat16                     : False\n",
      "COMET INFO:     config/use_return_dict                  : True\n",
      "COMET INFO:     config/vocab_size                       : 4101\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info          : 1\n",
      "COMET INFO:     conda-specification : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Couldn't find a Git repository in '/home/jovyan' nor in any parent directory. You can override where Comet is looking for a Git Patch by setting the configuration `COMET_GIT_DIRECTORY`\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/simecek/huggingface/ce23c086086946bfb726124a6ef80b18\n",
      "\n",
      "Automatic Comet.ml online logging enabled\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15254' max='15254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15254/15254 3:02:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.595562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 97625\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./model/checkpoint-15254\n",
      "Configuration saved in ./model/checkpoint-15254/config.json\n",
      "Model weights saved in ./model/checkpoint-15254/pytorch_model.bin\n",
      "Deleting older checkpoint [model/checkpoint-380000] due to args.save_total_limit\n",
      "Deleting older checkpoint [model/checkpoint-390000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./model/checkpoint-15254 (score: 0.595561683177948).\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/simecek/huggingface/ce23c086086946bfb726124a6ef80b18\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     epoch [32]               : (0.03, 1.0)\n",
      "COMET INFO:     eval_loss                : 0.595561683177948\n",
      "COMET INFO:     eval_runtime             : 277.9271\n",
      "COMET INFO:     eval_samples_per_second  : 351.261\n",
      "COMET INFO:     eval_steps_per_second    : 10.978\n",
      "COMET INFO:     learning_rate [30]       : (8.358463353874394e-07, 4.836108561688737e-05)\n",
      "COMET INFO:     loss [30]                : (0.8976, 7.5479)\n",
      "COMET INFO:     total_flos               : 1.2931977142656e+17\n",
      "COMET INFO:     train_loss               : 4.995824088365078\n",
      "COMET INFO:     train_runtime            : 10964.3805\n",
      "COMET INFO:     train_samples_per_second : 89.038\n",
      "COMET INFO:     train_steps_per_second   : 1.391\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     Created from : transformers\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     args/_n_gpu                             : 1\n",
      "COMET INFO:     args/_no_sync_in_gradient_accumulation  : True\n",
      "COMET INFO:     args/_setup_devices                     : cuda:0\n",
      "COMET INFO:     args/adafactor                          : False\n",
      "COMET INFO:     args/adam_beta1                         : 0.9\n",
      "COMET INFO:     args/adam_beta2                         : 0.999\n",
      "COMET INFO:     args/adam_epsilon                       : 1e-08\n",
      "COMET INFO:     args/auto_find_batch_size               : False\n",
      "COMET INFO:     args/bf16                               : False\n",
      "COMET INFO:     args/bf16_full_eval                     : False\n",
      "COMET INFO:     args/data_seed                          : None\n",
      "COMET INFO:     args/dataloader_drop_last               : False\n",
      "COMET INFO:     args/dataloader_num_workers             : 0\n",
      "COMET INFO:     args/dataloader_pin_memory              : True\n",
      "COMET INFO:     args/ddp_bucket_cap_mb                  : None\n",
      "COMET INFO:     args/ddp_find_unused_parameters         : None\n",
      "COMET INFO:     args/debug                              : []\n",
      "COMET INFO:     args/deepspeed                          : None\n",
      "COMET INFO:     args/device                             : cuda:0\n",
      "COMET INFO:     args/disable_tqdm                       : False\n",
      "COMET INFO:     args/do_eval                            : True\n",
      "COMET INFO:     args/do_predict                         : False\n",
      "COMET INFO:     args/do_train                           : False\n",
      "COMET INFO:     args/eval_accumulation_steps            : None\n",
      "COMET INFO:     args/eval_batch_size                    : 32\n",
      "COMET INFO:     args/eval_delay                         : 0\n",
      "COMET INFO:     args/eval_steps                         : None\n",
      "COMET INFO:     args/evaluation_strategy                : IntervalStrategy.EPOCH\n",
      "COMET INFO:     args/fp16                               : True\n",
      "COMET INFO:     args/fp16_backend                       : auto\n",
      "COMET INFO:     args/fp16_full_eval                     : False\n",
      "COMET INFO:     args/fp16_opt_level                     : O1\n",
      "COMET INFO:     args/fsdp                               : []\n",
      "COMET INFO:     args/fsdp_min_num_params                : 0\n",
      "COMET INFO:     args/full_determinism                   : False\n",
      "COMET INFO:     args/gradient_accumulation_steps        : 2\n",
      "COMET INFO:     args/gradient_checkpointing             : False\n",
      "COMET INFO:     args/greater_is_better                  : False\n",
      "COMET INFO:     args/group_by_length                    : False\n",
      "COMET INFO:     args/half_precision_backend             : amp\n",
      "COMET INFO:     args/hub_model_id                       : None\n",
      "COMET INFO:     args/hub_private_repo                   : False\n",
      "COMET INFO:     args/hub_strategy                       : HubStrategy.EVERY_SAVE\n",
      "COMET INFO:     args/hub_token                          : None\n",
      "COMET INFO:     args/ignore_data_skip                   : False\n",
      "COMET INFO:     args/include_inputs_for_metrics         : False\n",
      "COMET INFO:     args/label_names                        : None\n",
      "COMET INFO:     args/label_smoothing_factor             : 0.0\n",
      "COMET INFO:     args/learning_rate                      : 5e-05\n",
      "COMET INFO:     args/length_column_name                 : length\n",
      "COMET INFO:     args/load_best_model_at_end             : True\n",
      "COMET INFO:     args/local_process_index                : 0\n",
      "COMET INFO:     args/local_rank                         : -1\n",
      "COMET INFO:     args/log_level                          : -1\n",
      "COMET INFO:     args/log_level_replica                  : -1\n",
      "COMET INFO:     args/log_on_each_node                   : True\n",
      "COMET INFO:     args/logging_dir                        : ./model/runs/Jun21_00-36-36_jupyter-simecek\n",
      "COMET INFO:     args/logging_first_step                 : False\n",
      "COMET INFO:     args/logging_nan_inf_filter             : True\n",
      "COMET INFO:     args/logging_steps                      : 500\n",
      "COMET INFO:     args/logging_strategy                   : IntervalStrategy.STEPS\n",
      "COMET INFO:     args/lr_scheduler_type                  : SchedulerType.LINEAR\n",
      "COMET INFO:     args/max_grad_norm                      : 1.0\n",
      "COMET INFO:     args/max_steps                          : -1\n",
      "COMET INFO:     args/metric_for_best_model              : loss\n",
      "COMET INFO:     args/mp_parameters                      : \n",
      "COMET INFO:     args/n_gpu                              : 1\n",
      "COMET INFO:     args/no_cuda                            : False\n",
      "COMET INFO:     args/num_train_epochs                   : 1\n",
      "COMET INFO:     args/optim                              : OptimizerNames.ADAMW_HF\n",
      "COMET INFO:     args/output_dir                         : ./model\n",
      "COMET INFO:     args/overwrite_output_dir               : True\n",
      "COMET INFO:     args/parallel_mode                      : ParallelMode.NOT_PARALLEL\n",
      "COMET INFO:     args/past_index                         : -1\n",
      "COMET INFO:     args/per_device_eval_batch_size         : 32\n",
      "COMET INFO:     args/per_device_train_batch_size        : 32\n",
      "COMET INFO:     args/per_gpu_eval_batch_size            : None\n",
      "COMET INFO:     args/per_gpu_train_batch_size           : None\n",
      "COMET INFO:     args/place_model_on_device              : True\n",
      "COMET INFO:     args/prediction_loss_only               : False\n",
      "COMET INFO:     args/process_index                      : 0\n",
      "COMET INFO:     args/push_to_hub                        : False\n",
      "COMET INFO:     args/push_to_hub_model_id               : None\n",
      "COMET INFO:     args/push_to_hub_organization           : None\n",
      "COMET INFO:     args/push_to_hub_token                  : None\n",
      "COMET INFO:     args/remove_unused_columns              : True\n",
      "COMET INFO:     args/report_to                          : ['comet_ml']\n",
      "COMET INFO:     args/resume_from_checkpoint             : None\n",
      "COMET INFO:     args/run_name                           : ./model\n",
      "COMET INFO:     args/save_on_each_node                  : False\n",
      "COMET INFO:     args/save_steps                         : 500\n",
      "COMET INFO:     args/save_strategy                      : IntervalStrategy.EPOCH\n",
      "COMET INFO:     args/save_total_limit                   : 1\n",
      "COMET INFO:     args/seed                               : 42\n",
      "COMET INFO:     args/sharded_ddp                        : []\n",
      "COMET INFO:     args/should_log                         : True\n",
      "COMET INFO:     args/should_save                        : True\n",
      "COMET INFO:     args/skip_memory_metrics                : True\n",
      "COMET INFO:     args/tf32                               : None\n",
      "COMET INFO:     args/tpu_metrics_debug                  : False\n",
      "COMET INFO:     args/tpu_num_cores                      : None\n",
      "COMET INFO:     args/train_batch_size                   : 32\n",
      "COMET INFO:     args/use_legacy_prediction_loop         : False\n",
      "COMET INFO:     args/warmup_ratio                       : 0.0\n",
      "COMET INFO:     args/warmup_steps                       : 0\n",
      "COMET INFO:     args/weight_decay                       : 0.0\n",
      "COMET INFO:     args/world_size                         : 1\n",
      "COMET INFO:     args/xpu_backend                        : None\n",
      "COMET INFO:     config/_auto_class                      : None\n",
      "COMET INFO:     config/_name_or_path                    : \n",
      "COMET INFO:     config/add_cross_attention              : False\n",
      "COMET INFO:     config/architectures                    : None\n",
      "COMET INFO:     config/attention_probs_dropout_prob     : 0.1\n",
      "COMET INFO:     config/attribute_map                    : {}\n",
      "COMET INFO:     config/bad_words_ids                    : None\n",
      "COMET INFO:     config/bos_token_id                     : None\n",
      "COMET INFO:     config/chunk_size_feed_forward          : 0\n",
      "COMET INFO:     config/cross_attention_hidden_size      : None\n",
      "COMET INFO:     config/decoder_start_token_id           : None\n",
      "COMET INFO:     config/diversity_penalty                : 0.0\n",
      "COMET INFO:     config/do_sample                        : False\n",
      "COMET INFO:     config/early_stopping                   : False\n",
      "COMET INFO:     config/encoder_no_repeat_ngram_size     : 0\n",
      "COMET INFO:     config/eos_token_id                     : None\n",
      "COMET INFO:     config/exponential_decay_length_penalty : None\n",
      "COMET INFO:     config/finetuning_task                  : None\n",
      "COMET INFO:     config/forced_bos_token_id              : None\n",
      "COMET INFO:     config/forced_eos_token_id              : None\n",
      "COMET INFO:     config/hidden_act                       : gelu\n",
      "COMET INFO:     config/hidden_dropout_prob              : 0.1\n",
      "COMET INFO:     config/hidden_size                      : 768\n",
      "COMET INFO:     config/id2label                         : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "COMET INFO:     config/initializer_range                : 0.02\n",
      "COMET INFO:     config/intermediate_size                : 3072\n",
      "COMET INFO:     config/is_composition                   : False\n",
      "COMET INFO:     config/is_decoder                       : False\n",
      "COMET INFO:     config/is_encoder_decoder               : False\n",
      "COMET INFO:     config/label2id                         : {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "COMET INFO:     config/layer_norm_eps                   : 1e-07\n",
      "COMET INFO:     config/length_penalty                   : 1.0\n",
      "COMET INFO:     config/max_length                       : 20\n",
      "COMET INFO:     config/max_position_embeddings          : 512\n",
      "COMET INFO:     config/max_relative_positions           : -1\n",
      "COMET INFO:     config/min_length                       : 0\n",
      "COMET INFO:     config/model_type                       : deberta\n",
      "COMET INFO:     config/name_or_path                     : \n",
      "COMET INFO:     config/no_repeat_ngram_size             : 0\n",
      "COMET INFO:     config/num_attention_heads              : 12\n",
      "COMET INFO:     config/num_beam_groups                  : 1\n",
      "COMET INFO:     config/num_beams                        : 1\n",
      "COMET INFO:     config/num_hidden_layers                : 6\n",
      "COMET INFO:     config/num_labels                       : 2\n",
      "COMET INFO:     config/num_return_sequences             : 1\n",
      "COMET INFO:     config/output_attentions                : False\n",
      "COMET INFO:     config/output_hidden_states             : False\n",
      "COMET INFO:     config/output_scores                    : False\n",
      "COMET INFO:     config/pad_token_id                     : 0\n",
      "COMET INFO:     config/pooler_dropout                   : 0\n",
      "COMET INFO:     config/pooler_hidden_act                : gelu\n",
      "COMET INFO:     config/pooler_hidden_size               : 768\n",
      "COMET INFO:     config/pos_att_type                     : None\n",
      "COMET INFO:     config/position_biased_input            : True\n",
      "COMET INFO:     config/prefix                           : None\n",
      "COMET INFO:     config/problem_type                     : None\n",
      "COMET INFO:     config/pruned_heads                     : {}\n",
      "COMET INFO:     config/relative_attention               : False\n",
      "COMET INFO:     config/remove_invalid_values            : False\n",
      "COMET INFO:     config/repetition_penalty               : 1.0\n",
      "COMET INFO:     config/return_dict                      : True\n",
      "COMET INFO:     config/return_dict_in_generate          : False\n",
      "COMET INFO:     config/sep_token_id                     : None\n",
      "COMET INFO:     config/task_specific_params             : None\n",
      "COMET INFO:     config/temperature                      : 1.0\n",
      "COMET INFO:     config/tie_encoder_decoder              : False\n",
      "COMET INFO:     config/tie_word_embeddings              : True\n",
      "COMET INFO:     config/tokenizer_class                  : None\n",
      "COMET INFO:     config/top_k                            : 50\n",
      "COMET INFO:     config/top_p                            : 1.0\n",
      "COMET INFO:     config/torch_dtype                      : None\n",
      "COMET INFO:     config/torchscript                      : False\n",
      "COMET INFO:     config/transformers_version             : None\n",
      "COMET INFO:     config/type_vocab_size                  : 0\n",
      "COMET INFO:     config/typical_p                        : 1.0\n",
      "COMET INFO:     config/use_bfloat16                     : False\n",
      "COMET INFO:     config/use_return_dict                  : True\n",
      "COMET INFO:     config/vocab_size                       : 4101\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info          : 1\n",
      "COMET INFO:     conda-specification : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     os packages         : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: Comet has disabled auto-logging functionality as it has been imported after the following ML modules: torch. Metrics and hyperparameters can still be logged using comet_ml.log_metrics() and comet_ml.log_parameters()\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15254, training_loss=4.995824088365078, metrics={'train_runtime': 10964.3805, 'train_samples_per_second': 89.038, 'train_steps_per_second': 1.391, 'total_flos': 1.2931977142656e+17, 'train_loss': 4.995824088365078, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=chunked_datasets['train'],\n",
    "    eval_dataset=chunked_datasets['test'],\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UohJaPiWdlVb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model_stride1/config.json\n",
      "Model weights saved in model_stride1/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 97625\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3051' max='3051' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3051/3051 04:37]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5963960886001587,\n",
       " 'eval_runtime': 277.867,\n",
       " 'eval_samples_per_second': 351.337,\n",
       " 'eval_steps_per_second': 10.98,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model_stride1\")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xkbB-0iyt4v"
   },
   "source": [
    "## Finetuning - stride K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "InVMXXg7ywBK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_strideK/config.json\n",
      "Model config DebertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"DebertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": null,\n",
      "  \"position_biased_input\": true,\n",
      "  \"relative_attention\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 4101\n",
      "}\n",
      "\n",
      "loading weights file model_strideK/pytorch_model.bin\n",
      "Some weights of the model checkpoint at model_strideK were not used when initializing DebertaForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at model_strideK and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaForSequenceClassification\n",
    "\n",
    "model_cls = DebertaForSequenceClassification.from_pretrained(\"model_strideK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_C7mdPSn-0Pl"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tmp_dict = {}\n",
    "\n",
    "for dset in ['train', 'test']:\n",
    "  for c in ['negative', 'positive']:\n",
    "    for f in Path(f'/home/jovyan/.genomic_benchmarks/human_nontata_promoters/{dset}/{c}/').glob('*.txt'):\n",
    "      txt = f.read_text()\n",
    "      tmp_dict[f.stem] = (dset, int(c == \"positive\"), txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "e_DP-co1EFZF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dset</th>\n",
       "      <th>cat</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>CCATTGTAAGCAAAATGGATTATGAAAATTAATTTTACACAGGAAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>TTCACATCAATTGCTGCTTCAGGGATCACAGATTTTAGGGGCTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14233</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>GGAGTCAGAATATCCTGTTCCTCAACAGACTCTTTTACCTAGTGGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3266</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>GCTACTTGGTGAACTCTGGCATTGTTCCCATCTCGAGAAGTCTCAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8629</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>GAGCCTTCATTCTTGGTCAAGCTTTAGGCACATCTGAGTGAGTAGT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP003064</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGGGTGATTAAGGTGAAGCGTTTCTTCCATTACTGGTAGAACGAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP014906</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>CTCGATATTTTTTTTCTGAGATCTTCCCCTTGTTGTTAATACTAAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP015371</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>TCTGTCCCCCTCCCCCTCCCTGTCCTTATCTTTCCCTTCTGTCTCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP011060</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>GACGCCCCTTTGCTCCAGGCCCCGCCCCGGGGTCCCGCCTCCACCA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FP018699</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>GAGCGGGTGAGAGGAGCGGGACACGCGGAGGAGGTAAGGAAGGGGT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36131 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dset cat                                                seq\n",
       "13497     train   0  CCATTGTAAGCAAAATGGATTATGAAAATTAATTTTACACAGGAAA...\n",
       "4964      train   0  TTCACATCAATTGCTGCTTCAGGGATCACAGATTTTAGGGGCTCAT...\n",
       "14233     train   0  GGAGTCAGAATATCCTGTTCCTCAACAGACTCTTTTACCTAGTGGT...\n",
       "3266      train   0  GCTACTTGGTGAACTCTGGCATTGTTCCCATCTCGAGAAGTCTCAT...\n",
       "8629      train   0  GAGCCTTCATTCTTGGTCAAGCTTTAGGCACATCTGAGTGAGTAGT...\n",
       "...         ...  ..                                                ...\n",
       "FP003064   test   1  GAGGGTGATTAAGGTGAAGCGTTTCTTCCATTACTGGTAGAACGAA...\n",
       "FP014906   test   1  CTCGATATTTTTTTTCTGAGATCTTCCCCTTGTTGTTAATACTAAT...\n",
       "FP015371   test   1  TCTGTCCCCCTCCCCCTCCCTGTCCTTATCTTTCCCTTCTGTCTCC...\n",
       "FP011060   test   1  GACGCCCCTTTGCTCCAGGCCCCGCCCCGGGGTCCCGCCTCCACCA...\n",
       "FP018699   test   1  GAGCGGGTGAGAGGAGCGGGACACGCGGAGGAGGTAAGGAAGGGGT...\n",
       "\n",
       "[36131 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(tmp_dict).T.rename(columns = {0: \"dset\", 1: \"cat\", 2: \"seq\"})\n",
    "#df.to_pickle(\"human_nontata_promoters.pkl\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_PVU18G60bSY"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "0vOSFljBx7Cu"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bb64d135e2444d95d0428afbd2412f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36131 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_func(x): return tokenizer(\" \".join(kmers(x[\"seq\"])))\n",
    "\n",
    "tok_ds = ds.map(tok_func, batched=False, remove_columns=['__index_level_0__', 'seq'])\n",
    "tok_ds = tok_ds.rename_columns({'cat':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "NAxnbRVp1oav"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b721cab588b948d69095fe27900d2341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b05576f6ea41c5a6ce0874309db19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dset', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27097\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dset', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9034\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = DatasetDict({\n",
    "    'train': tok_ds.filter(lambda x: x[\"dset\"] == \"train\"),\n",
    "    'test':  tok_ds.filter(lambda x: x[\"dset\"] == \"test\")\n",
    "})\n",
    "\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Aj8C9lAB4Oxd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "bs = 32\n",
    "epochs = CLS_EPOCHS\n",
    "lr = 8e-5\n",
    "\n",
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "5lGUDmG_4fWG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(model_cls, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokenizer, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "iC1oEy7w4saV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 27097\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3388' max='3388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3388/3388 02:17, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.388517</td>\n",
       "      <td>0.850232</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.441780</td>\n",
       "      <td>0.844809</td>\n",
       "      <td>0.855553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.461455</td>\n",
       "      <td>0.842595</td>\n",
       "      <td>0.854809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.525967</td>\n",
       "      <td>0.826987</td>\n",
       "      <td>0.846328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to outputs/checkpoint-500\n",
      "Configuration saved in outputs/checkpoint-500/config.json\n",
      "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-1000\n",
      "Configuration saved in outputs/checkpoint-1000/config.json\n",
      "Model weights saved in outputs/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to outputs/checkpoint-1500\n",
      "Configuration saved in outputs/checkpoint-1500/config.json\n",
      "Model weights saved in outputs/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-2000\n",
      "Configuration saved in outputs/checkpoint-2000/config.json\n",
      "Model weights saved in outputs/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to outputs/checkpoint-2500\n",
      "Configuration saved in outputs/checkpoint-2500/config.json\n",
      "Model weights saved in outputs/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-3000\n",
      "Configuration saved in outputs/checkpoint-3000/config.json\n",
      "Model weights saved in outputs/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "XcS_f8zpHENw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/142 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5259673595428467,\n",
       " 'eval_accuracy': 0.8269869382333407,\n",
       " 'eval_f1': 0.8463277947104512,\n",
       " 'eval_runtime': 2.9488,\n",
       " 'eval_samples_per_second': 3063.606,\n",
       " 'eval_steps_per_second': 48.155,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjdFXSMAiKn6"
   },
   "source": [
    "## Finetuning - stride 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "EOthVn2uiKn8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model_stride1/config.json\n",
      "Model config DebertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"DebertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": null,\n",
      "  \"position_biased_input\": true,\n",
      "  \"relative_attention\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 4101\n",
      "}\n",
      "\n",
      "loading weights file model_stride1/pytorch_model.bin\n",
      "Some weights of the model checkpoint at model_stride1 were not used when initializing DebertaForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at model_stride1 and are newly initialized: ['classifier.bias', 'pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_cls = DebertaForSequenceClassification.from_pretrained(\"model_stride1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "DhYUMJqaiKoA"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6906bf961dbc472a8ab914645848d4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36131 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tok_func_stride1(x): return tokenizer(\" \".join(kmers_stride1(x[\"seq\"])))\n",
    "\n",
    "tok_ds = ds.map(tok_func_stride1, batched=False, remove_columns=['__index_level_0__', 'seq'])\n",
    "tok_ds = tok_ds.rename_columns({'cat':'labels'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UBoRI2TtiKoA"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c315a637e14214b210002aeebfd784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0753c3e075c6457199840b3890835ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['dset', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 27097\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['dset', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9034\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = DatasetDict({\n",
    "    'train': tok_ds.filter(lambda x: x[\"dset\"] == \"train\"),\n",
    "    'test':  tok_ds.filter(lambda x: x[\"dset\"] == \"test\")\n",
    "})\n",
    "\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ALSfMQCpiKoC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "The following columns in the training set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/jovyan/my-conda-envs/myEnv/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 27097\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3388' max='3388' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3388/3388 08:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.332948</td>\n",
       "      <td>0.845583</td>\n",
       "      <td>0.866392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.255100</td>\n",
       "      <td>0.273180</td>\n",
       "      <td>0.887425</td>\n",
       "      <td>0.895789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154400</td>\n",
       "      <td>0.286161</td>\n",
       "      <td>0.894620</td>\n",
       "      <td>0.903311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.343791</td>\n",
       "      <td>0.898162</td>\n",
       "      <td>0.905930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to outputs/checkpoint-500\n",
      "Configuration saved in outputs/checkpoint-500/config.json\n",
      "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-1000\n",
      "Configuration saved in outputs/checkpoint-1000/config.json\n",
      "Model weights saved in outputs/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to outputs/checkpoint-1500\n",
      "Configuration saved in outputs/checkpoint-1500/config.json\n",
      "Model weights saved in outputs/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-1500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-2000\n",
      "Configuration saved in outputs/checkpoint-2000/config.json\n",
      "Model weights saved in outputs/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to outputs/checkpoint-2500\n",
      "Configuration saved in outputs/checkpoint-2500/config.json\n",
      "Model weights saved in outputs/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-2500/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to outputs/checkpoint-3000\n",
      "Configuration saved in outputs/checkpoint-3000/config.json\n",
      "Model weights saved in outputs/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in outputs/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in outputs/checkpoint-3000/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model_cls, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokenizer, compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "pI2NVPcWiKoD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaForSequenceClassification.forward` and have been ignored: dset. If dset are not expected by `DebertaForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9034\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='142' max='142' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [142/142 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.34379133582115173,\n",
       " 'eval_accuracy': 0.8981624972326766,\n",
       " 'eval_f1': 0.9059304703476483,\n",
       " 'eval_runtime': 12.3272,\n",
       " 'eval_samples_per_second': 732.851,\n",
       " 'eval_steps_per_second': 11.519,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9g0rDKfh1OM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KMER_Experiment_K5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:myEnv]",
   "language": "python",
   "name": "conda-env-myEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0079fe2fe6cc43a9adc0f99c5b30c84c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0eb46c03dec34c018e07f2667f93368e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "143014fcfd2a4a2b9e2c491bfab7f9ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8116c3cff4cc418eb6c2fc47a6efb452",
       "IPY_MODEL_257c7591a5164e4fa315cb0517644844",
       "IPY_MODEL_f87e6706919a4501b81ac93ea4eec735"
      ],
      "layout": "IPY_MODEL_0079fe2fe6cc43a9adc0f99c5b30c84c"
     }
    },
    "257c7591a5164e4fa315cb0517644844": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e0c348e60c54d4397245ab5fbeddea5",
      "max": 40,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e700c36f519340269f44366380538cba",
      "value": 40
     }
    },
    "6e0c348e60c54d4397245ab5fbeddea5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8116c3cff4cc418eb6c2fc47a6efb452": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0eb46c03dec34c018e07f2667f93368e",
      "placeholder": "​",
      "style": "IPY_MODEL_a94aa776214f4d59893a812e768cc11e",
      "value": "Downloading: 100%"
     }
    },
    "82577495709c40ea966f0a5667fd7aaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a94aa776214f4d59893a812e768cc11e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be092e02e18c436d9d72bf49c06ef50a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e700c36f519340269f44366380538cba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f87e6706919a4501b81ac93ea4eec735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82577495709c40ea966f0a5667fd7aaa",
      "placeholder": "​",
      "style": "IPY_MODEL_be092e02e18c436d9d72bf49c06ef50a",
      "value": " 40.0/40.0 [00:00&lt;00:00, 311B/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
